

【最终版】增量更新重构文档

好的！我们已经达成一致，目标是重构系统，让消费者能够简单地获取“最终状态”数据。我们将采用最高效的**Vec<bool>脏标记方案，并在数据拉取时采用边读边清、失败告警**的策略，以在已知稳定环境中实现最高性能和最低的逻辑复杂度。

这个修改会涉及 KlineAggregator 的结构体定义和它的两个核心方法：finalize_and_snapshot_kline 和 process_deltas_request。

下面是详细的修改方案。

第1步：修改 KlineAggregator 结构体

我们需要在 KlineAggregator 中去掉 deltas_buffer，换成 dirty_flags。

文件路径: src/klagg_sub_threads/mod.rs

修改逻辑:

移除 deltas_buffer: Vec<KlineData>。

移除 deltas_buffer_capacity: usize。

增加 dirty_flags: Vec<bool>。

Generated rust,ignore
// src/klagg_sub_threads/mod.rs

pub struct KlineAggregator {
    periods: Arc<Vec<String>>,
    kline_expirations: Vec<i64>,
    kline_states: Vec<KlineState>,

    // --- [核心修改] ---
    /// 使用布尔向量作为脏标记，与kline_states一一对应
    dirty_flags: Vec<bool>,
    // --- [旧字段被移除] ---
    // deltas_buffer: Vec<KlineData>,
    // deltas_buffer_capacity: usize,

    /// [修改] local_symbol_cache 语义变更为全量热路径缓存 (symbol -> global_index)
    local_symbol_cache: HashMap<String, usize>,
    managed_symbols_count: usize,
    // ... (其他字段保持不变)
}

第2步：修改 KlineAggregator::new 初始化方法

我们需要在创建 KlineAggregator 实例时，正确地初始化 dirty_flags。

文件路径: src/klagg_sub_threads/mod.rs

修改逻辑:

在计算出 total_slots 后，创建一个等长的 Vec<bool> 并全部初始化为 false。

移除 deltas_buffer 和 deltas_buffer_capacity 的初始化代码。

在填充初始K线状态后，需要将对应的 dirty_flags 标记为 true，以确保这些初始状态能被第一次拉取到。

Generated rust,ignore
// src/klagg_sub_threads/mod.rs -> impl KlineAggregator

pub async fn new(
    // ... (签名不变)
) -> Result<(Self, mpsc::Receiver<WsCmd>, mpsc::Receiver<AggTradeData>)> {
    // ... (前面逻辑不变)

    // [修改] 使用配置中的 max_symbols，更加灵活健壮
    let capacity_symbols = config.max_symbols;
    let total_slots = capacity_symbols * num_periods;

    let mut kline_states = vec![KlineState::default(); total_slots];
    let mut kline_expirations = vec![i64::MAX; total_slots];
    // [核心修改] 初始化 dirty_flags
    let mut dirty_flags = vec![false; total_slots];

    // 【旧代码移除】
    // let buffer_capacity = config.buffer.deltas_buffer_capacity;
    // let deltas_buffer = Vec::with_capacity(buffer_capacity);

    let mut local_symbol_cache = HashMap::with_capacity(assigned_symbols.len());

    let guard = symbol_to_global_index.read().await;
    for symbol in assigned_symbols {
        if let Some(&global_index) = guard.get(symbol) {
            local_symbol_cache.insert(symbol.clone(), global_index);

            // ... (解析 db_kline 的逻辑不变)

            for (period_idx, period) in periods.iter().enumerate() {
                let kline_offset = global_index * num_periods + period_idx;
                
                match initial_klines.get(&(symbol.clone(), period.clone())) {
                    Some(db_kline) => {
                        // ... (填充 kline_states 和 kline_expirations 的逻辑不变)

                        // [核心修改] 标记初始状态为“脏”，以便被第一次拉取
                        if kline_offset < dirty_flags.len() {
                            dirty_flags[kline_offset] = true;
                        }
                    }
                    None => {
                        // ... (错误处理不变)
                    }
                }
            }
        }
    }

    let aggregator = Self {
        periods,
        kline_expirations,
        kline_states,
        dirty_flags, // [核心修改]
        // [旧字段移除]
        // deltas_buffer,
        // deltas_buffer_capacity: buffer_capacity,
        local_symbol_cache,
        // ... (其他字段赋值不变)
    };

    info!(target: "计算核心", log_type="low_freq", "KlineAggregator 实例已创建并完成初始状态填充和索引构建");
    Ok((aggregator, ws_cmd_rx, trade_rx))
}
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Rust,ignore
IGNORE_WHEN_COPYING_END
第3步：修改 finalize_and_snapshot_kline

这是“生产”增量的核心环节。我们需要改变它的行为，从push到buffer改为设置脏标记。

文件路径: src/klagg_sub_threads/mod.rs

修改逻辑:

移除 push 到 deltas_buffer 的逻辑。

增加一行代码，将对应 kline_offset 的 dirty_flags 设置为 true。

Generated rust,ignore
// src/klagg_sub_threads/mod.rs -> impl KlineAggregator

fn finalize_and_snapshot_kline(&mut self, kline_offset: usize, final_close: f64, is_final: bool) {
    let old_kline = &mut self.kline_states[kline_offset];
    if old_kline.is_final && is_final { return; }
    old_kline.close = final_close;
    old_kline.is_final = is_final;

    // [核心修改] 不再创建和push快照，只设置脏标记
    if kline_offset < self.dirty_flags.len() {
        self.dirty_flags[kline_offset] = true;
    } else {
        error!(
            target: "计算核心",
            log_type = "assertion",
            kline_offset,
            dirty_flags_len = self.dirty_flags.len(),
            "finalize_and_snapshot_kline: 偏移量越界！"
        );
    }

    // [旧代码移除]
    // let global_symbol_index = kline_offset / self.periods.len();
    // let period_idx = kline_offset % self.periods.len();
    // let kline_data = KlineData { ... };
    // self.deltas_buffer.push(kline_data);
}
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Rust,ignore
IGNORE_WHEN_COPYING_END

注意: process_trade 和 rollover_kline 等调用 finalize_and_snapshot_kline 的地方无需任何改动，这是此修改的优雅之处。

第4步：修改 process_deltas_request

这是“消费”增量的核心环节。我们重写它的逻辑，采用最高性能的边读边清策略。

文件路径: src/klagg_sub_threads/mod.rs

修改逻辑:

完全替换原有函数体。

使用 iter_mut() 遍历 dirty_flags，找出所有为 true 的项。

在遍历过程中，立即将 true 置为 false。

根据索引从 kline_states 中收集数据，打包成 Vec<KlineData>。

发送数据。如果发送失败，不进行任何回滚，而是打印一条ERROR级别的日志，明确指出发生了数据丢失，将问题暴露给监控和运维。

Generated rust,ignore
// src/klagg_sub_threads/mod.rs -> impl KlineAggregator

/// [核心修改] 增量请求处理逻辑，改为遍历时清理并接受失败时的数据丢失
#[instrument(target = "计算核心", level = "debug", skip(self, response_tx))]
fn process_deltas_request(&mut self, response_tx: oneshot::Sender<Vec<KlineData>>) {
    let mut final_states_snapshot = Vec::new();
    let mut cleaned_indices_count = 0; // 用于日志记录

    // 使用iter_mut()在一次遍历中完成检查、清理和收集
    for (i, is_dirty_ref) in self.dirty_flags.iter_mut().enumerate() {
        if *is_dirty_ref {
            // 立即清理脏标记
            *is_dirty_ref = false;

            // 确保我们只处理已初始化的K线
            if self.kline_states[i].is_initialized {
                let state = &self.kline_states[i];
                let global_symbol_index = i / self.periods.len();
                let period_index = i % self.periods.len();
                
                final_states_snapshot.push(KlineData {
                    global_symbol_index,
                    period_index,
                    open_time: state.open_time,
                    open: state.open,
                    high: state.high,
                    low: state.low,
                    close: state.close,
                    volume: state.volume,
                    turnover: state.turnover,
                    trade_count: state.trade_count,
                    taker_buy_volume: state.taker_buy_volume,
                    taker_buy_turnover: state.taker_buy_turnover,
                    is_final: state.is_final,
                });
                
                cleaned_indices_count += 1;
            }
        }
    }

    // 尝试发送打包好的最终状态数据
    if response_tx.send(final_states_snapshot).is_err() {
        // [最终决策] 发送失败，我们不回滚。
        // 这意味着本轮更新数据已丢失。
        // 打出ERROR日志并触发告警，将问题暴露给运维层面。
        error!(
            target: "计算核心",
            log_type = "DATA_LOSS",
            lost_data_count = cleaned_indices_count,
            "增量数据发送失败，本轮更新已在计算核心丢失！请立即检查网关或下游消费者状态！"
        );
    }
    // 发送成功，则任务完美完成，无需额外操作。
}
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Rust,ignore
IGNORE_WHEN_COPYING_END

现在，你可以让你本地的AI应用以上所有修改。这个最终方案将计算核心的性能和简洁性推向了极致，并与你对项目的定位和环境的判断完全吻合。