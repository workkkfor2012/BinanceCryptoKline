好的，遵照您的指示。我将综合我们之前讨论的所有要点——特别是聚焦于 “AI友好型日志”、“陈述式验证”、“上下文证据” 和 “0到1阶段的实用性” ——生成一份完整的、可以直接交付给另一个AI进行审核和实施的最终版“Cerberus”系统设计文档。

这份文档包含了三个部分：

Phase 1 (MVP) 实现计划： 宏观的项目管理和实施路线图。

技术架构设计： 深入到核心组件和设计模式。

验证规则详细说明： 提供了具体、可操作的、“AI友好型”的验证逻辑。

这份文档的目标是：清晰、明确、无歧义，让任何一个强大的AI模型都能理解其设计哲学并高质量地完成代码实现。

交付文档：Cerberus 超级断言系统 - AI实施最终版

--- START OF FILE 1_Cerberus_实现计划_Final.md ---

🐕 Cerberus 超级断言系统 | AI实施最终版计划
📋 项目概述

项目代号: "Cerberus" (地狱三头犬)
核心目标: 构建一个运行时验证引擎，它通过生成“AI友好型”的结构化日志，将程序的内部状态和逻辑路径“翻译”成可供AI分析的“程序自述报告”，从而在0到1的快速开发阶段，最大程度地自动化功能验证和Debug过程。
设计理念: 日志即规格 (Log as Spec)。程序的每一次运行，都是一次对自身规格的完整自检。

🎯 Phase 1 (MVP) 范围定义
验证的核心：“陈述”与“偏差”

我们将传统的“断言”思想转变为“陈述”。系统在关键节点“陈述”其预期状态，并记录实际状态与预期的对比。当出现不一致时，记录一个附带充足“上下文证据”的 DEVIATION (规格偏差) 日志事件，而不是中断程序。

验证的广度 (Breadth) - 关键路径全覆盖

数据有效性: INGESTION_DATA_VALIDITY (包含与历史数据的对比)

路由健康度: ROUTING_SUCCESS_RATE

元数据稳定性: SYMBOL_INDEX_STABILITY

K线内部逻辑: KLINE_OHLC_CONSISTENCY, KLINE_OPEN_TIME_ACCURACY, KLINE_MONOTONIC_INCREASE

双缓冲机制: BUFFER_SWAP_INTEGRITY

数据持久化: PERSISTENCE_DATA_CONSISTENCY (包含采样回读验证)

验证的深度 (Depth) - 聚焦“短时记忆”

实现一个轻量级的、有状态验证器，用于验证紧邻的事件序列（如单调性）。

状态管理采用基于 TTL (Time-To-Live) 的自动清理机制，避免内存泄漏，无需复杂的LRU。

验证的时序性 (Timeliness) - 聚焦“瓶颈发现”

利用 tracing::Span 自动捕获关键函数的执行耗时。

提供一个简单的 Top 10 性能瓶颈报告，而非复杂的实时延迟监控。

🏗️ 核心架构设计
主要组件
Generated code
CerberusEngine (核心验证引擎)
├── ValidationRuleRegistry (规则注册表)
├── ShortTermStateManager (短时状态管理器)
└── PerformanceReporter (性能报告器)

设计原则

日志优先: 所有验证结果都以结构化的、富含上下文的JSON日志形式输出。

非阻塞式: 验证逻辑在独立的任务中异步执行，不阻塞核心业务线程。

AI友好: DEVIATION 日志必须包含“实际值”、“期望值”、“上下文证据”等字段，便于AI分析。

运行时可控: 支持全局禁用和按规则级别调整，保障生产环境安全。

📁 文件结构规划
新增核心文件
Generated code
src/klaggregate/cerberus/
├── mod.rs              # Cerberus 模块声明与集成
├── engine.rs           # CerberusEngine 核心实现
├── rules.rs            # Phase 1 所有验证规则的具体实现
└── types.rs            # Cerberus 专用数据类型 (e.g., ValidationContext, DeviationEvent)
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END
现有文件集成点

在所有相关业务模块文件中，通过 tracing::instrument 和 tracing::info! 埋点，由 Cerberus 的 TracingLayer 统一捕获和处理，实现零侵入式集成。

🚀 实施步骤 (7天冲刺计划)
Day 1-2: 基础架构搭建

创建 cerberus 模块及核心文件。

定义 ValidationContext, DeviationEvent 等核心类型。

实现 CerberusEngine 骨架和异步验证任务队列。

实现 ShortTermStateManager，使用 DashMap + TTL 清理。

构建 CerberusLayer (作为 tracing::Layer)，实现从tracing::Event到ValidationContext的转换。

交付物: 可集成到 tracing 的基础框架，能够处理事件但无具体规则。

Day 3-4: 静态与逻辑规则实现

在 rules.rs 中实现以下规则：

INGESTION_DATA_VALIDITY (包含上下文对比)

SYMBOL_INDEX_STABILITY

KLINE_OHLC_CONSISTENCY (包含逻辑闭环验证)

KLINE_OPEN_TIME_ACCURACY

编写对应的单元测试，验证规则逻辑的正确性。

交付物: 核心的无状态验证规则全部实现并通过单元测试。

Day 5: 有状态与机制规则实现

在 rules.rs 中实现以下规则：

ROUTING_SUCCESS_RATE (有状态)

KLINE_MONOTONIC_INCREASE (有状态)

BUFFER_SWAP_INTEGRITY

PERSISTENCE_DATA_CONSISTENCY (包含采样回读)

集成并测试 ShortTermStateManager。

交付物: 有状态验证功能正常工作，系统能够验证事件序列。

Day 6: 性能监控与集成

实现 PerformanceReporter，在 CerberusLayer 的 on_close 钩子中收集span耗时。

实现Top 10性能瓶颈报告功能。

将 CerberusLayer 正式集成到主程序的 tracing subscriber 中。

进行端到端集成测试，确保所有模块的日志都能被正确捕获和验证。

交付物: 系统完整集成，性能报告功能可用。

Day 7: 调优、文档与收尾

对异步验证任务的调度进行性能调优。

编写 README.md，详细说明如何使用Cerberus，如何解读其日志，以及如何扩展新规则。

清理代码，添加注释，准备最终交付。

交付物: 一个文档齐全、经过测试和优化的生产就绪的 Cerberus Phase 1 系统。

--- START OF FILE 2_Cerberus_技术架构设计_Final.md ---

🏗️ Cerberus 技术架构设计 | AI实施最终版
📐 系统架构概览
Generated mermaid
graph TB
    subgraph "业务模块 (通过 Tracing Events 通信)"
        MDI[MarketDataIngestor]
        TER[TradeEventRouter]
        SKA[SymbolKlineAggregator]
        BKS[BufferedKlineStore]
        KDP[KlineDataPersistence]
        SMR[SymbolMetadataRegistry]
    end

    subgraph "Cerberus 验证引擎 (作为 Tracing Layer 运行)"
        CL[CerberusLayer]
        CE[CerberusEngine]
        VRR[ValidationRuleRegistry]
        SSM[ShortTermStateManager]
        PR[PerformanceReporter]

        CL --> CE
        CE --> VRR
        CE --> SSM
        CE --> PR
    end

    subgraph "验证规则"
        Rules[rules.rs]
    end
    
    subgraph "AI & 日志系统"
        AI[AI分析模型]
        Logs[结构化日志 (JSON)]
    end

    MDI --> CL
    TER --> CL
    SKA --> CL
    BKS --> CL
    KDP --> CL
    SMR --> CL

    VRR --> Rules
    CE --> Logs
    Logs --> AI
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Mermaid
IGNORE_WHEN_COPYING_END
🔧 核心组件设计
CerberusLayer - Tracing 集成层

作为 tracing::Layer 的实现，是 Cerberus 的唯一入口。
职责:

事件拦截: 拦截所有 tracing::Event。

上下文转换: 将 Event 及其 span 数据转换为统一的 ValidationContext。

异步分发: 将 ValidationContext 发送到 CerberusEngine 的后台任务队列，不阻塞业务线程。

性能捕获: 在 on_close 钩子中，将关闭的 span 信息（ID，名称，耗时）发送给 PerformanceReporter。

CerberusEngine - 验证引擎核心

运行在一个或多个独立的后台任务中。
职责:

从任务队列中接收 ValidationContext。

查询 ValidationRuleRegistry 以获取适用于该上下文的规则列表。

对每个规则，执行其验证逻辑。如果是有状态规则，则通过 ShortTermStateManager 获取或更新其状态。

将验证结果（特别是 DEVIATION 事件）格式化为JSON并输出到日志。

ValidationRuleRegistry - 规则注册表

一个简单的 HashMap 或 Vec，在引擎启动时从 rules.rs 中加载所有规则。
职责:

存储所有已实现的验证规则。

提供一个 get_applicable_rules(&context) 方法，根据context.target（模块名）和context.event_name快速过滤出需要执行的规则。

ShortTermStateManager - 短时状态管理器

职责:

提供一个线程安全的 get_or_create_state<T>(&key, creator) 方法。

内部使用 DashMap<String, StateEntry>。

StateEntry 包含 Arc<RwLock<T>> 和一个last_access_time。

一个独立的 tokio 定时任务每分钟运行一次，清理所有last_access_time超过预设TTL（如5分钟）的状态。

PerformanceReporter - 性能报告器

职责:

在内存中维护一个 DashMap<String, PerfStats>，key是span的名称。

PerfStats 结构包含 count, total_duration, max_duration。

提供一个 generate_report() 方法，计算平均耗时并排序，返回Top N性能瓶颈报告。

🎯 验证规则架构
Generated rust
// file: cerberus/rules.rs

// 所有规则实现的入口
pub fn get_all_rules() -> Vec<Arc<dyn ValidationRule>> {
    vec![
        // 在这里注册所有规则实例
        Arc::new(IngestionDataValidityRule),
        Arc::new(KlineOhlcConsistencyRule),
        // ...
    ]
}

// 单个规则的实现示例
struct KlineOhlcConsistencyRule;
impl ValidationRule for KlineOhlcConsistencyRule {
    fn id(&self) -> &str { "KLINE_OHLC_CONSISTENCY" }
    
    fn is_applicable(&self, context: &ValidationContext) -> bool {
        // 只对特定的事件感兴趣
        context.target == "SymbolKlineAggregator" && context.event_name == "kline_updated"
    }

    fn validate(&self, context: &ValidationContext) -> ValidationResult {
        // 从 context.fields 中提取 kline 数据
        // 执行验证逻辑...
        // 返回 ValidationResult::Pass 或 ValidationResult::Deviation
    }
}
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Rust
IGNORE_WHEN_COPYING_END
🔄 验证流程设计
Generated mermaid
sequenceDiagram
    participant App as 业务代码
    participant Tracing as tracing::info!
    participant Layer as CerberusLayer
    participant Engine as CerberusEngine (后台任务)
    participant Log as 日志输出
    participant AI as AI分析

    App->>Tracing: tracing::info!(target="...", event_name="...", ...)
    Tracing->>Layer: on_event(event)
    Layer->>Engine: send_to_queue(context)
    App-->>Tracing: (主线程继续，无阻塞)

    Engine->>Engine: receive_from_queue(context)
    Engine->>Engine: for rule in applicable_rules
    Engine->>Engine:   result = rule.validate(context)
    alt result is Deviation
        Engine->>Log: log_deviation(result)
    end
    
    Log->>AI: AI读取并分析日志
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Mermaid
IGNORE_WHEN_COPYING_END

--- START OF FILE 3_Cerberus_验证规则说明_Final.md ---

📋 Cerberus 验证规则详细说明 | AI实施最终版
🎯 核心原则：为AI提供证据

每个DEVIATION事件都必须是一个自包含的、富含上下文的“案发现场报告”。它必须包含**“实际值”、“预期/对比值”和“触发源”**，以便AI能够直接进行根本原因分析。

📊 详细规则说明
1. INGESTION_DATA_VALIDITY (Critical)

目标: 验证进入系统的每一笔交易数据的合理性。
触发点: MarketDataIngestor 解析出 AggTradeData。
验证逻辑:

价格波动验证:

陈述: 当前交易价格与该品种上一次记录的价格相比，波动率应在±50%以内。

证据 (DEVIATION时): {"received_price": 1.23, "last_known_price": 65000.12, "volatility": "5300000%"}

时间戳验证:

陈述: 交易时间戳与当前服务器时间的差距应在±5分钟内。

证据: {"trade_timestamp": "...", "server_timestamp": "...", "diff_ms": 3600001}

品种有效性验证:

陈述: 交易品种必须存在于系统启动时加载的品种列表中。

证据: {"symbol": "INVALIDCOINUSDT", "is_known_symbol": false}

2. KLINE_OHLC_CONSISTENCY (Critical)

目标: 保证K线内部数据的逻辑自洽。
触发点: SymbolKlineAggregator 中K线数据被更新后。
验证逻辑:

OHLC关系验证:

陈述: K线的low <= high。

证据: {"kline_state": {"low": 65, "high": 55}, "triggering_trade": {"price": 55}}

成交额闭环验证:

陈述: 成交额约等于“平均价 * 成交量”。

证据: {"turnover": 1000, "volume": 100, "avg_price": 1.5, "expected_turnover_approx": 150, "diff_percentage": "85%"}

3. KLINE_MONOTONIC_INCREASE (Standard, 有状态)

目标: 确保K线的聚合指标（如成交量）只增不减。
触发点: SymbolKlineAggregator 中K线数据被更新后。
验证逻辑:

陈述: 当前K线的volume必须大于或等于上一个状态的volume。

证据: {"metric": "volume", "value_before": 100.5, "value_after": 95.5, "triggering_trade": {"quantity": -5.0}} (如果能追溯到的话)

4. BUFFER_SWAP_INTEGRITY (Critical)

目标: 验证双缓冲交换的原子性和数据完整性。
触发点: BufferedKlineStore 的调度器执行交换后。
验证逻辑:

数据完整性采样验证:

陈述: 交换后，新的“读缓冲区”的数据，必须与交换前的“写缓冲区”的数据完全一致。

证据: （在DEVIATION时记录）随机抽取一个索引进行对比。{"check_index": 123, "value_before_swap": "...", "value_after_swap": "..."}

5. PERSISTENCE_DATA_CONSISTENCY (Standard)

目标: 验证数据从内存到数据库的链路是无损的。
触发点: KlineDataPersistence 完成一次批量写入后。
验证逻辑:

采样回读验证:

陈述: 以1%的概率，随机抽取本次持久化批次中的一条数据，在写入后立刻回读，内存与数据库中的数据应完全一致。

证据: {"check_on_kline": {"symbol": "BTCUSDT", "open_time": "..."}, "memory_data": "{...}", "database_data": "{...}", "diff_fields": ["close", "volume"]}

这份三合一的文档为您和另一个AI提供了一个清晰、一致、可执行的蓝图。它强调了您最初的目标——创建一个能让AI大显身手的、高度可观测和可验证的系统，并将其融入到了每一个设计细节中。