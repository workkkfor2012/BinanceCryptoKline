#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Trace æ—¥å¿—åˆ†æå·¥å…·
åˆ†æ TraceDistiller ç”Ÿæˆçš„å‡½æ•°æ‰§è¡Œè·¯å¾„å¿«ç…§ï¼Œæä¾›è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š
"""

import sys
import re
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

@dataclass
class TraceNode:
    """è¡¨ç¤ºè°ƒç”¨æ ‘ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹"""
    name: str
    duration_ms: Optional[float] = None
    self_time_ms: Optional[float] = None
    is_critical_path: bool = False
    has_error: bool = False
    fields: Dict[str, str] = None
    children: List['TraceNode'] = None
    depth: int = 0

    def __post_init__(self):
        if self.fields is None:
            self.fields = {}
        if self.children is None:
            self.children = []

class TraceAnalyzer:
    """Trace æ—¥å¿—åˆ†æå™¨"""

    def __init__(self, log_file: str):
        self.log_file = Path(log_file)
        self.traces: List[Dict] = []
        self.root_nodes: List[TraceNode] = []


    def parse_log_file(self) -> bool:
        """è§£ææ—¥å¿—æ–‡ä»¶"""
        if not self.log_file.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.log_file}")
            return False

        print(f"ğŸ“– æ­£åœ¨è§£ææ–‡ä»¶: {self.log_file}")

        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æŒ‰ Trace åˆ†å‰²å†…å®¹
            trace_sections = re.split(r'------------------ End of Trace [0-9a-fx]+ ------------------', content)

            for section in trace_sections:
                if '=== å‡½æ•°æ‰§è¡Œè·¯å¾„åˆ†ææŠ¥å‘Š ===' in section:
                    trace_info = self._parse_trace_section(section)
                    if trace_info:
                        self.traces.append(trace_info)

            print(f"âœ… æˆåŠŸè§£æ {len(self.traces)} ä¸ª Trace")
            return True

        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥: {e}")
            return False

    def _parse_trace_section(self, section: str) -> Optional[Dict]:
        """è§£æå•ä¸ª Trace æ®µè½"""
        lines = section.strip().split('\n')
        if not lines:
            return None

        trace_info = {
            'trace_id': None,
            'root_function': None,
            'total_duration': None,
            'status': None,
            'call_tree': None
        }

        # è§£æå¤´éƒ¨ä¿¡æ¯
        for line in lines:
            if 'Trace ID:' in line:
                trace_info['trace_id'] = line.split('Trace ID:')[1].strip()
            elif 'æ ¹å‡½æ•°:' in line:
                trace_info['root_function'] = line.split('æ ¹å‡½æ•°:')[1].strip()
            elif 'æ€»è€—æ—¶:' in line:
                duration_match = re.search(r'(\d+\.?\d*)ms', line)
                if duration_match:
                    trace_info['total_duration'] = float(duration_match.group(1))
            elif 'æ‰§è¡ŒçŠ¶æ€:' in line:
                trace_info['status'] = 'æˆåŠŸ' if 'âœ…' in line else 'å¤±è´¥'
            elif '=== è°ƒç”¨æ ‘ç»“æ„ ===' in line:
                # æ‰¾åˆ°è°ƒç”¨æ ‘å¼€å§‹ä½ç½®ï¼Œè·³è¿‡æ ¼å¼è¯´æ˜è¡Œ
                tree_start_idx = lines.index(line)
                # è·³è¿‡æ ¼å¼è¯´æ˜è¡Œï¼Œæ‰¾åˆ°çœŸæ­£çš„è°ƒç”¨æ ‘å¼€å§‹
                actual_start = tree_start_idx + 1
                while actual_start < len(lines):
                    line_content = lines[actual_start].strip()
                    # è·³è¿‡æ ¼å¼è¯´æ˜å’Œç©ºè¡Œ
                    if (line_content and
                        not line_content.startswith('æ ¼å¼:') and
                        not line_content.startswith('ğŸ”¥') and
                        not line_content.startswith('âŒ') and
                        '=' not in line_content and
                        line_content != ''):
                        break
                    actual_start += 1

                tree_lines = lines[actual_start:]
                trace_info['call_tree'] = self._parse_call_tree(tree_lines)
                break

        return trace_info if trace_info['trace_id'] else None


    def _parse_call_tree(self, tree_lines: List[str]) -> TraceNode:
        """è§£æè°ƒç”¨æ ‘ç»“æ„"""
        if not tree_lines:
            return None

        root = None
        node_stack = []  # (node, depth)

        # å¼€å§‹è§£æè°ƒç”¨æ ‘

        for line_num, line in enumerate(tree_lines):
            if not line.strip() or line.startswith('===') or 'é”™è¯¯ä¿¡æ¯æ±‡æ€»' in line:
                break

            node = self._parse_tree_line(line)
            if node is None:
                continue

            if root is None:
                root = node
                node_stack = [(root, node.depth)]
                if not hasattr(self, 'root_nodes'):
                    self.root_nodes = []
                self.root_nodes.append(root)  # æ·»åŠ åˆ°æ ¹èŠ‚ç‚¹åˆ—è¡¨
            else:
                # æ‰¾åˆ°æ­£ç¡®çš„çˆ¶èŠ‚ç‚¹
                while node_stack and node_stack[-1][1] >= node.depth:
                    node_stack.pop()

                if node_stack:
                    parent = node_stack[-1][0]
                    parent.children.append(node)
                else:
                    # å¦‚æœæ²¡æœ‰åˆé€‚çš„çˆ¶èŠ‚ç‚¹ï¼Œå¯èƒ½æ˜¯æ–°çš„æ ¹èŠ‚ç‚¹
                    if not hasattr(self, 'root_nodes'):
                        self.root_nodes = []
                    self.root_nodes.append(node)

                node_stack.append((node, node.depth))

        return root
    def _parse_tree_line(self, line: str) -> Optional[TraceNode]:
        """è§£æè°ƒç”¨æ ‘çš„å•è¡Œ"""
        original_line = line

        # ç§»é™¤æ ‘å½¢è¿æ¥ç¬¦ï¼Œä½†ä¿ç•™ç¼©è¿›ä¿¡æ¯
        # æ ‘å½¢è¿æ¥ç¬¦åŒ…æ‹¬: â”‚ â”œ â”” â”€ ä»¥åŠç©ºæ ¼
        clean_line = re.sub(r'^(\s*)[â”‚â”œâ””â”€\s]*', r'\1', line)

        # è®¡ç®—å®é™…çš„ç¼©è¿›æ·±åº¦ï¼ˆåŸºäºåŸå§‹ç¼©è¿›ï¼‰
        leading_spaces = len(line) - len(line.lstrip())
        # æ¯3ä¸ªå­—ç¬¦ä¸ºä¸€å±‚ç¼©è¿›ï¼Œä½†éœ€è¦è€ƒè™‘æ ‘å½¢è¿æ¥ç¬¦çš„å½±å“
        # æ ‘å½¢è¿æ¥ç¬¦é€šå¸¸å ç”¨3ä¸ªå­—ç¬¦ä½ç½®ï¼š'   ', 'â”œâ”€ ', 'â””â”€ ', 'â”‚  '
        depth = leading_spaces // 3

        content = clean_line.strip()
        if not content:
            return None

        # è§£ææ ‡è®°
        is_critical = 'ğŸ”¥' in content
        has_error = 'âŒ' in content
        content = re.sub(r'[ğŸ”¥âŒ]\s*', '', content)

        # è§£æå‡½æ•°åå’Œæ—¶é—´ä¿¡æ¯
        # æ ¼å¼: function_name (123.45ms | 67.89ms) [param=value]
        match = re.match(r'([^\(]+)\s*\(([^)]+)\)(?:\s*\[([^\]]+)\])?', content)

        if not match:
            # å¦‚æœæ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œå°è¯•ç®€å•è§£æ
            simple_match = re.match(r'([^\s\(]+)', content)
            if simple_match:
                name = simple_match.group(1).strip()
                return TraceNode(
                    name=name,
                    duration_ms=None,
                    self_time_ms=None,
                    is_critical_path=is_critical,
                    has_error=has_error,
                    fields={},
                    depth=depth
                )
            return None

        name = match.group(1).strip()
        timing_info = match.group(2)
        fields_info = match.group(3) if match.group(3) else ""

        # è§£ææ—¶é—´ä¿¡æ¯
        duration_ms = None
        self_time_ms = None

        if '|' in timing_info:
            parts = timing_info.split('|')
            duration_match = re.search(r'(-?\d+\.?\d*)ms', parts[0])
            self_time_match = re.search(r'(-?\d+\.?\d*)ms', parts[1])

            if duration_match:
                duration_ms = float(duration_match.group(1))
            if self_time_match:
                self_time_ms = float(self_time_match.group(1))
        else:
            duration_match = re.search(r'(-?\d+\.?\d*)ms', timing_info)
            if duration_match:
                duration_ms = float(duration_match.group(1))

        # è§£æå­—æ®µä¿¡æ¯
        fields = {}
        if fields_info:
            for field in fields_info.split(','):
                if '=' in field:
                    key, value = field.split('=', 1)
                    fields[key.strip()] = value.strip()

        return TraceNode(
            name=name,
            duration_ms=duration_ms,
            self_time_ms=self_time_ms,
            is_critical_path=is_critical,
            has_error=has_error,
            fields=fields,
            depth=depth
        )

    def analyze(self) -> Dict:
        """æ‰§è¡Œåˆ†æå¹¶è¿”å›ç»“æœ"""
        if not self.traces:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ Trace æ•°æ®"}

        analysis = {
            "summary": self._generate_summary(),
            "performance_analysis": self._analyze_performance(),
            "error_analysis": self._analyze_errors(),
            "function_statistics": self._analyze_functions(),
            "recommendations": self._generate_recommendations()
        }

        return analysis

    def _generate_summary(self) -> Dict:
        """ç”Ÿæˆæ€»ä½“æ‘˜è¦"""
        total_traces = len(self.traces)
        successful_traces = sum(1 for t in self.traces if t['status'] == 'æˆåŠŸ')
        failed_traces = total_traces - successful_traces

        total_duration = sum(t['total_duration'] for t in self.traces if t['total_duration'])
        avg_duration = total_duration / len([t for t in self.traces if t['total_duration']]) if total_duration else 0

        return {
            "total_traces": total_traces,
            "successful_traces": successful_traces,
            "failed_traces": failed_traces,
            "success_rate": f"{(successful_traces/total_traces*100):.1f}%" if total_traces > 0 else "0%",
            "total_duration_ms": total_duration,
            "average_duration_ms": avg_duration
        }

    def _analyze_performance(self) -> Dict:
        """åˆ†ææ€§èƒ½æ•°æ®"""
        durations = [t['total_duration'] for t in self.traces if t['total_duration']]

        if not durations:
            return {"error": "æ²¡æœ‰æœ‰æ•ˆçš„æ€§èƒ½æ•°æ®"}

        durations.sort()

        return {
            "min_duration_ms": min(durations),
            "max_duration_ms": max(durations),
            "median_duration_ms": durations[len(durations)//2],
            "p95_duration_ms": durations[int(len(durations)*0.95)] if len(durations) > 1 else durations[0],
            "slowest_traces": self._get_slowest_traces(3)
        }

    def _analyze_errors(self) -> Dict:
        """åˆ†æé”™è¯¯ä¿¡æ¯"""
        failed_traces = [t for t in self.traces if t['status'] == 'å¤±è´¥']

        return {
            "total_errors": len(failed_traces),
            "error_rate": f"{(len(failed_traces)/len(self.traces)*100):.1f}%" if self.traces else "0%",
            "failed_functions": [t['root_function'] for t in failed_traces]
        }

    def _analyze_functions(self) -> Dict:
        """åˆ†æå‡½æ•°ç»Ÿè®¡"""
        function_stats = {}

        for trace in self.traces:
            if trace['call_tree']:
                self._collect_function_stats(trace['call_tree'], function_stats)

        # æŒ‰è°ƒç”¨æ¬¡æ•°æ’åº
        sorted_functions = sorted(function_stats.items(), key=lambda x: x[1]['count'], reverse=True)

        return {
            "total_unique_functions": len(function_stats),
            "most_called_functions": sorted_functions[:10],
            "function_details": function_stats
        }

    def _collect_function_stats(self, node: TraceNode, stats: Dict):
        """é€’å½’æ”¶é›†å‡½æ•°ç»Ÿè®¡ä¿¡æ¯"""
        if node.name not in stats:
            stats[node.name] = {
                'count': 0,
                'total_duration': 0,
                'total_self_time': 0,
                'error_count': 0
            }

        stats[node.name]['count'] += 1
        if node.duration_ms:
            stats[node.name]['total_duration'] += node.duration_ms
        if node.self_time_ms:
            stats[node.name]['total_self_time'] += node.self_time_ms
        if node.has_error:
            stats[node.name]['error_count'] += 1

        for child in node.children:
            self._collect_function_stats(child, stats)

    def _get_slowest_traces(self, count: int) -> List[Dict]:
        """è·å–æœ€æ…¢çš„å‡ ä¸ª Trace"""
        sorted_traces = sorted(
            [t for t in self.traces if t['total_duration']],
            key=lambda x: x['total_duration'],
            reverse=True
        )

        return sorted_traces[:count]

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        durations = [t['total_duration'] for t in self.traces if t['total_duration']]
        if durations:
            max_duration = max(durations)
            avg_duration = sum(durations) / len(durations)

            if max_duration > avg_duration * 3:
                recommendations.append(f"âš ï¸  å‘ç°å¼‚å¸¸æ…¢çš„æ‰§è¡Œè·¯å¾„ï¼Œæœ€æ…¢è€—æ—¶ {max_duration:.2f}msï¼Œå»ºè®®æ£€æŸ¥æ€§èƒ½ç“¶é¢ˆ")

            if avg_duration > 1000:
                recommendations.append(f"âš ï¸  å¹³å‡æ‰§è¡Œæ—¶é—´è¾ƒé•¿ ({avg_duration:.2f}ms)ï¼Œå»ºè®®ä¼˜åŒ–å…³é”®è·¯å¾„")

        failed_count = len([t for t in self.traces if t['status'] == 'å¤±è´¥'])
        if failed_count > 0:
            recommendations.append(f"âŒ å‘ç° {failed_count} ä¸ªå¤±è´¥çš„æ‰§è¡Œè·¯å¾„ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯å¤„ç†")

        if not recommendations:
            recommendations.append("âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæœªå‘ç°æ˜æ˜¾é—®é¢˜")

        return recommendations

    def print_analysis(self, analysis: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š TRACE åˆ†ææŠ¥å‘Š")
        print("="*60)

        # æ€»ä½“æ‘˜è¦
        summary = analysis['summary']
        print(f"\nğŸ“ˆ æ€»ä½“æ‘˜è¦:")
        print(f"  æ€» Trace æ•°é‡: {summary['total_traces']}")
        print(f"  æˆåŠŸæ‰§è¡Œ: {summary['successful_traces']} ({summary['success_rate']})")
        print(f"  æ‰§è¡Œå¤±è´¥: {summary['failed_traces']}")
        print(f"  æ€»è€—æ—¶: {summary['total_duration_ms']:.2f}ms")
        print(f"  å¹³å‡è€—æ—¶: {summary['average_duration_ms']:.2f}ms")

        # æ€§èƒ½åˆ†æ
        if 'error' not in analysis['performance_analysis']:
            perf = analysis['performance_analysis']
            print(f"\nâš¡ æ€§èƒ½åˆ†æ:")
            print(f"  æœ€å¿«æ‰§è¡Œ: {perf['min_duration_ms']:.2f}ms")
            print(f"  æœ€æ…¢æ‰§è¡Œ: {perf['max_duration_ms']:.2f}ms")
            print(f"  ä¸­ä½æ•°: {perf['median_duration_ms']:.2f}ms")
            print(f"  95åˆ†ä½æ•°: {perf['p95_duration_ms']:.2f}ms")

            print(f"\nğŸŒ æœ€æ…¢çš„æ‰§è¡Œè·¯å¾„:")
            for i, trace in enumerate(perf['slowest_traces'], 1):
                print(f"  {i}. {trace['root_function']} - {trace['total_duration']:.2f}ms")

        # é”™è¯¯åˆ†æ
        errors = analysis['error_analysis']
        if errors['total_errors'] > 0:
            print(f"\nâŒ é”™è¯¯åˆ†æ:")
            print(f"  é”™è¯¯æ•°é‡: {errors['total_errors']} ({errors['error_rate']})")
            print(f"  å¤±è´¥çš„å‡½æ•°: {', '.join(errors['failed_functions'])}")

        # å‡½æ•°ç»Ÿè®¡
        func_stats = analysis['function_statistics']
        print(f"\nğŸ”§ å‡½æ•°ç»Ÿè®¡:")
        print(f"  å”¯ä¸€å‡½æ•°æ•°é‡: {func_stats['total_unique_functions']}")
        print(f"  è°ƒç”¨æœ€é¢‘ç¹çš„å‡½æ•°:")
        for func_name, stats in func_stats['most_called_functions'][:5]:
            avg_duration = stats['total_duration'] / stats['count'] if stats['count'] > 0 else 0
            print(f"    {func_name}: {stats['count']}æ¬¡è°ƒç”¨, å¹³å‡{avg_duration:.2f}ms")

        # ä¼˜åŒ–å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for rec in analysis['recommendations']:
            print(f"  {rec}")

        print("\n" + "="*60)

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python analyze_trace.py <trace_log_file>")
        sys.exit(1)

    log_file = sys.argv[1]
    analyzer = TraceAnalyzer(log_file)

    if not analyzer.parse_log_file():
        sys.exit(1)

    analysis = analyzer.analyze()
    analyzer.print_analysis(analysis)

if __name__ == "__main__":
    main()