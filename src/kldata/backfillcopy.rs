use crate::klcommon::{BinanceApi, Database, DownloadTask, Result, AppError};
use crate::klcommon::api::get_aligned_time;
use tracing::{debug, info, warn, error, instrument, Instrument};
use std::sync::Arc;
use std::collections::HashMap;
use std::time::{Instant, Duration};
use std::sync::atomic::{AtomicUsize, Ordering};
use once_cell::sync::Lazy;
// æ—¶é—´æˆ³ç›¸å…³å¯¼å…¥å·²ç§»è‡³ timestamp_checker.rs

// å…¨å±€ç»Ÿè®¡å˜é‡ï¼Œç”¨äºè·Ÿè¸ªè¡¥é½Kçº¿çš„æ•°é‡å’Œæ—¥å¿—æ˜¾ç¤º
// æ ¼å¼: (è¡¥é½Kçº¿æ€»æ•°, æœ€åæ—¥å¿—æ—¶é—´, äº¤æ˜“å¯¹ç»Ÿè®¡Map)
static BACKFILL_STATS: Lazy<(AtomicUsize, std::sync::Mutex<Instant>, std::sync::Mutex<HashMap<String, usize>>)> = Lazy::new(|| {
    (AtomicUsize::new(0), std::sync::Mutex::new(Instant::now()), std::sync::Mutex::new(HashMap::new()))
});

// å…¨å±€APIè¯·æ±‚è®¡æ•°å™¨
// æ ¼å¼: (å‘é€çš„è¯·æ±‚æ•°, æˆåŠŸçš„è¯·æ±‚æ•°, å¤±è´¥çš„è¯·æ±‚æ•°)
static API_REQUEST_STATS: Lazy<(AtomicUsize, AtomicUsize, AtomicUsize)> = Lazy::new(|| {
    (AtomicUsize::new(0), AtomicUsize::new(0), AtomicUsize::new(0))
});

// æ—¥å¿—é—´éš”ï¼Œæ¯30ç§’è¾“å‡ºä¸€æ¬¡æ‘˜è¦
const BACKFILL_LOG_INTERVAL: u64 = 30;

/// Kçº¿æ•°æ®è¡¥é½æ¨¡å—
pub struct KlineBackfiller {
    db: Arc<Database>,
    api: BinanceApi,
    intervals: Vec<String>,
    test_mode: bool,
    test_symbols: Vec<String>,
}

impl KlineBackfiller {
    /// åˆ›å»ºæ–°çš„Kçº¿è¡¥é½å™¨å®ä¾‹
    pub fn new(db: Arc<Database>, intervals: Vec<String>) -> Self {
        let api = BinanceApi::new();
        Self {
            db,
            api,
            intervals,
            test_mode: false,
            test_symbols: vec![],
        }
    }

    /// åˆ›å»ºæµ‹è¯•æ¨¡å¼çš„Kçº¿è¡¥é½å™¨å®ä¾‹
    pub fn new_test_mode(db: Arc<Database>, intervals: Vec<String>, test_symbols: Vec<String>) -> Self {
        let api = BinanceApi::new();
        Self {
            db,
            api,
            intervals,
            test_mode: true,
            test_symbols,
        }
    }

    /// æ›´æ–°è¡¥é½Kçº¿çš„ç»Ÿè®¡ä¿¡æ¯å¹¶æ¯30ç§’è¾“å‡ºä¸€æ¬¡æ‘˜è¦æ—¥å¿—
    fn update_backfill_stats(symbol: &str, interval: &str, count: usize) {
        // æ›´æ–°æ€»è®¡æ•°å™¨
        BACKFILL_STATS.0.fetch_add(count, Ordering::Relaxed);

        // æ›´æ–°æŒ‰äº¤æ˜“å¯¹å’Œå‘¨æœŸçš„è®¡æ•°å™¨
        let key = format!("{}/{}", symbol, interval);
        let mut symbol_map = BACKFILL_STATS.2.lock().unwrap();
        let entry = symbol_map.entry(key).or_insert(0);
        *entry += count;

        // æ£€æŸ¥æ˜¯å¦éœ€è¦è¾“å‡ºæ—¥å¿—
        let mut last_log_time = BACKFILL_STATS.1.lock().unwrap();
        let now = Instant::now();
        let elapsed = now.duration_since(*last_log_time);

        // å¦‚æœæ—¥å¿—é—´éš”å·²è¿‡ï¼Œè¾“å‡ºæ—¥å¿—å¹¶é‡ç½®è®¡æ•°å™¨
        if elapsed >= Duration::from_secs(BACKFILL_LOG_INTERVAL) {
            let total_count = BACKFILL_STATS.0.swap(0, Ordering::Relaxed);

            if total_count > 0 {
                // æ„å»ºç®€æ´çš„æ‘˜è¦ä¿¡æ¯ï¼Œä¸åŒ…å«è¯¦ç»†çš„äº¤æ˜“å¯¹ä¿¡æ¯
                let summary = format!("è¡¥é½Kçº¿æ‘˜è¦ ({}ç§’): æ€»è®¡ {} æ¡Kçº¿",
                    BACKFILL_LOG_INTERVAL, total_count);

                // è¾“å‡ºæ—¥å¿—
                info!(log_type = "low_freq", target = "backfill", "{}", summary);
            }

            // æ¸…ç©ºäº¤æ˜“å¯¹è®¡æ•°å™¨
            symbol_map.clear();

            // æ›´æ–°æœ€åæ—¥å¿—æ—¶é—´
            *last_log_time = now;
        } else {
            // å¦‚æœä¸éœ€è¦è¾“å‡ºæ—¥å¿—ï¼Œåˆ™è¾“å‡ºè°ƒè¯•æ—¥å¿—

        }
    }

    /// è¿è¡Œä¸€æ¬¡æ€§è¡¥é½æµç¨‹
    #[instrument(name = "backfill_run_once", target = "backfill", skip_all)]
    pub async fn run_once(&self) -> Result<()> {
        info!(log_type = "low_freq", target = "backfill", "å¼€å§‹ä¸€æ¬¡æ€§è¡¥é½Kçº¿æ•°æ®...");
        let start_time = Instant::now();

        // 1. è·å–äº¤æ˜“å¯¹åˆ—è¡¨
        let all_symbols = if self.test_mode {
            info!(log_type = "module", target = "backfill", "ğŸ”§ æµ‹è¯•æ¨¡å¼å·²å¯ç”¨ï¼Œé™åˆ¶äº¤æ˜“å¯¹ä¸º: {:?}", self.test_symbols);
            self.test_symbols.clone()
        } else {
            info!(log_type = "module", target = "backfill", "ğŸ“¡ è·å–æ‰€æœ‰æ­£åœ¨äº¤æ˜“çš„Uæœ¬ä½æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹...");
            match self.api.get_trading_usdt_perpetual_symbols().await {
                Ok((trading_symbols, _delisted_symbols)) => {
                    info!(log_type = "module", target = "backfill", "âœ… è·å–åˆ° {} ä¸ªäº¤æ˜“å¯¹", trading_symbols.len());
                    trading_symbols
                },
                Err(e) => {
                    // è·å–äº¤æ˜“å¯¹å¤±è´¥æ˜¯ä¸¥é‡é”™è¯¯ï¼Œç›´æ¥è¿”å›é”™è¯¯å¹¶ç»“æŸç¨‹åº
                    error!(log_type = "module", target = "backfill", "âŒ è·å–äº¤æ˜“å¯¹ä¿¡æ¯å¤±è´¥: {}", e);
                    return Err(AppError::ApiError(format!("è·å–äº¤æ˜“å¯¹ä¿¡æ¯å¤±è´¥: {}", e)));
                }
            }
        };

        // å¦‚æœæ²¡æœ‰è·å–åˆ°äº¤æ˜“å¯¹ï¼Œç›´æ¥è¿”å›é”™è¯¯
        if all_symbols.is_empty() {
            error!(log_type = "module", target = "backfill", "æ²¡æœ‰è·å–åˆ°äº¤æ˜“å¯¹ï¼Œè¡¥é½æµç¨‹ç»“æŸ");
            return Err(AppError::ApiError("æ²¡æœ‰è·å–åˆ°äº¤æ˜“å¯¹ï¼Œæ— æ³•ç»§ç»­è¡¥é½æµç¨‹".to_string()));
        }

        // 2. åˆ›å»ºæ‰€æœ‰å¿…è¦çš„è¡¨
        self.ensure_all_tables(&all_symbols)?;

        // 3. åˆ›å»ºæ‰€æœ‰ä¸‹è½½ä»»åŠ¡ - å£°æ˜ä¸ºå¾ªç¯ä»¥ä¾¿TraceDistillerèšåˆ
        let task_creation_loop_span = tracing::info_span!(
            "task_creation_loop",
            target = "backfill",
            iterator_type = "SymbolInterval",
            task_count = all_symbols.len() * self.intervals.len()
        );

        let tasks = async {
            self.create_all_download_tasks(&all_symbols).await
        }.instrument(task_creation_loop_span).await?;

        info!(log_type = "module", target = "backfill", "åˆ›å»ºäº† {} ä¸ªä¸‹è½½ä»»åŠ¡ï¼ˆåŒ…æ‹¬è¡¥é½ä»»åŠ¡å’Œæ–°å“ç§å®Œæ•´ä¸‹è½½ä»»åŠ¡ï¼‰", tasks.len());

        if tasks.is_empty() {
            info!(log_type = "module", target = "backfill", "æ²¡æœ‰éœ€è¦è¡¥é½æˆ–ä¸‹è½½çš„Kçº¿æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®éƒ½æ˜¯æœ€æ–°çš„");
            return Ok(());
        }

        // åœ¨asyncå—å¤–éƒ¨å£°æ˜è¿™äº›å˜é‡ï¼Œä»¥ä¾¿åœ¨asyncå—ç»“æŸåä»èƒ½è®¿é—®
        let semaphore = Arc::new(tokio::sync::Semaphore::new(50)); // å¢åŠ åˆ°50ä¸ªå¹¶å‘ï¼Œå……åˆ†åˆ©ç”¨ç½‘ç»œå¸¦å®½ï¼Œå†™å…¥æ“ä½œç”±DbWriteQueueåºåˆ—åŒ–å¤„ç†
        let mut handles = Vec::new();
        // å­˜å‚¨å¤±è´¥ä»»åŠ¡åŠå…¶å¤±è´¥åŸå›  - ä½¿ç”¨æ›´ç®€å•çš„ç»“æ„
        let failed_tasks = Arc::new(tokio::sync::Mutex::new(Vec::new()));
        // å­˜å‚¨å¤±è´¥åŸå› çš„ç»Ÿè®¡
        let error_reasons = Arc::new(tokio::sync::Mutex::new(std::collections::HashMap::<String, usize>::new()));
        // åˆ›å»ºä¸€ä¸ªè®¡æ•°å™¨æ¥è·Ÿè¸ªæ·»åŠ åˆ°å¤±è´¥åˆ—è¡¨çš„ä»»åŠ¡æ•°é‡
        let failed_tasks_counter = Arc::new(std::sync::atomic::AtomicUsize::new(0));

        // âœ¨ã€å¿…é¡»çš„ä¿®æ”¹ã€‘âœ¨ 1. åŒ…è£¹ç¬¬ä¸€è½®ä¸‹è½½å¾ªç¯
        // æˆ‘ä»¬ç”¨ä¸€ä¸ªæ–°çš„ span æ¥æ¡†ä½æ•´ä¸ªæ‰¹é‡ä¸‹è½½çš„é€»è¾‘ã€‚
        // è¿™å°†æˆä¸ºæ‰€æœ‰ download_kline_task çš„çˆ¶ spanã€‚
        let initial_download_loop_span = tracing::info_span!(
            "initial_download_loop", // çº¦å®šçš„ `_loop` åç¼€
            target = "backfill",
            task_count = tasks.len(),
            concurrency = 50, // æ˜ç¡®æŒ‡å‡ºå¹¶å‘æ•°
            iterator_type = "DownloadTask"
        );

        // ä½¿ç”¨ .instrument() å°†è¿™ä¸ª span é™„åŠ åˆ°æ¥ä¸‹æ¥çš„å¼‚æ­¥å—ä¸Š
        let (_success_count, error_count) = async {

            for (task_index, task) in tasks.into_iter().enumerate() {
                let api_clone = self.api.clone();
                let semaphore_clone = semaphore.clone();
                let db_clone = self.db.clone();
                let failed_tasks_clone = failed_tasks.clone();
                let error_reasons_clone = error_reasons.clone();
                let failed_tasks_counter_clone = failed_tasks_counter.clone();
                let task_clone = task.clone();

                let _symbol = task.symbol.clone();
                let _interval = task.interval.clone();

                // âœ¨ã€å…³é”®ä¿®å¤ã€‘âœ¨ å…ˆå®šä¹‰futureï¼Œå°†spanåˆ›å»ºç§»åŠ¨åˆ°è·å–è®¸å¯ä¹‹å
                let download_future = async move {
                    // è·å–ä¿¡å·é‡è®¸å¯
                    let _permit = semaphore_clone.acquire().await.unwrap();

                    let symbol = task.symbol.clone();
                    let interval = task.interval.clone();

                    // âœ¨ã€å…³é”®ä¿®å¤ã€‘âœ¨ åœ¨è¿™é‡Œåˆ›å»ºspanï¼Œå®ƒåªåŒ…è£¹çœŸæ­£çš„ä¸‹è½½å’Œä¿å­˜å·¥ä½œ
                    let task_span = tracing::info_span!(
                        "download_kline_task",
                        symbol = %symbol,
                        interval = %interval,
                        target = "backfill",
                        task_index = task_index
                    );

                async move {
                    //debug!(target: "backfill", log_type = "module", "Starting task...");
                    
                    // è®°å½•APIè¯·æ±‚
                    let _request_id = API_REQUEST_STATS.0.fetch_add(1, Ordering::SeqCst);

                    //debug!(target: "backfill", log_type = "module", "Calling API...");
                    match api_clone.download_continuous_klines(&task).await {
                        Ok(klines) => {
                            //debug!(target: "backfill", log_type = "module", "API call successful, received {} klines.", klines.len());
                            API_REQUEST_STATS.1.fetch_add(1, Ordering::SeqCst);

                            if klines.is_empty() {
                                let error_msg = format!("{}/{}: API returned empty result", symbol, interval);
                                warn!(target: "backfill", log_type = "module", "{}", error_msg);
                                // This is not a critical error, so we don't add it to the failed_tasks list for retry.
                                // We simply return Ok to let the task complete.
                                return Ok(());
                            }

                            let mut sorted_klines = klines;
                            sorted_klines.sort_by_key(|k| k.open_time);

                            //debug!(target: "backfill", log_type = "module", "Saving to database...");
                            match db_clone.save_klines(&symbol, &interval, &sorted_klines).await {
                                Ok(count) => {
                                    //debug!(target: "backfill", log_type = "module", "Database save successful, {} klines saved. Task complete.", count);
                                    Self::update_backfill_stats(&symbol, &interval, count);
                                    Ok(())
                                }
                                Err(db_err) => {
                                    let error_msg = format!("Database save failed: {}", db_err);
                                    error!(target: "backfill", log_type = "module", "{}/{}: {}", symbol, interval, error_msg);
                                    
                                    // Add to failed tasks for retry
                                    let mut tasks = failed_tasks_clone.lock().await;
                                    tasks.push((task_clone.clone(), error_msg.clone()));
                                    failed_tasks_counter_clone.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                                    
                                    Err(AppError::DatabaseError(error_msg))
                                }
                            }
                        }
                        Err(e) => {
                            debug!(target: "backfill", log_type = "module", "API call failed.");
                            API_REQUEST_STATS.2.fetch_add(1, Ordering::SeqCst);

                            let error_msg = format!("API download failed: {}", e);
                            error!(target: "backfill", log_type = "module", "{}/{}: {}", symbol, interval, error_msg);

                            // Add to failed tasks for retry
                            let mut tasks = failed_tasks_clone.lock().await;
                            tasks.push((task_clone, error_msg.clone()));
                            failed_tasks_counter_clone.fetch_add(1, std::sync::atomic::Ordering::SeqCst);

                            Err(AppError::ApiError(error_msg))
                        }
                    }
                }.instrument(task_span).await
                };
               
                // âœ¨ã€æœ€ç»ˆä¿®å¤ã€‘âœ¨ åœ¨ spawn ä¹‹å‰ï¼Œç”¨çˆ¶ span çš„ä¸Šä¸‹æ–‡æ¥"åŒ…è£¹"è¿™ä¸ª future
                // `tracing::Span::current()` è·å–åˆ°çš„æ˜¯å½“å‰çš„ `initial_download_loop` span
                let instrumented_future = download_future.instrument(tracing::Span::current());
                let handle = tokio::spawn(instrumented_future); // spawn è¢«åŒ…è£¹åçš„ future
                handles.push(handle);
            }
            debug!(target: "backfill", log_type = "module", "ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ");
            // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            let mut success_count = 0;
            let mut error_count = 0;
            let total_handles = handles.len();

            info!(target: "backfill", log_type = "module",
                "å¼€å§‹ç­‰å¾…ä»»åŠ¡å®Œæˆå¾ªç¯ - æ€»ä»»åŠ¡æ•°: {}, å¹¶å‘æ•°: 50, é¢„æœŸæˆåŠŸç‡: >95%",
                total_handles
            );
           

            for (i, handle) in handles.into_iter().enumerate() {
                match handle.await {
                    Ok(result) => {
                        match result {
                            Ok(_) => {
                                success_count += 1;
                                if i % 100 == 0 {
                                    debug!(target = "backfill", "å·²å®Œæˆ {} ä¸ªä»»åŠ¡ï¼ŒæˆåŠŸ: {}, å¤±è´¥: {}", i+1, success_count, error_count);
                                }
                            },
                            Err(_) => {
                                error_count += 1;
                                if error_count % 10 == 0 {
                                    debug!(target = "backfill", "å·²å®Œæˆ {} ä¸ªä»»åŠ¡ï¼ŒæˆåŠŸ: {}, å¤±è´¥: {}", i+1, success_count, error_count);
                                }
                            },
                        }
                    }
                    Err(join_err) => { // Task panicked
                        error!(target = "backfill", "ä»»åŠ¡ #{} æ‰§è¡Œå› panicè€Œå¤±è´¥: {}", i + 1, join_err);
                        error_count += 1;
                        // æ³¨æ„ï¼šæ­¤å¤„panicçš„ä»»åŠ¡ç›®å‰ä¸ä¼šè¢«æ·»åŠ åˆ° failed_tasks åˆ—è¡¨ï¼Œå› ä¸ºåŸå§‹taskå¯¹è±¡ä¸æ˜“è·å–
                        // å¯ä»¥åœ¨æœ€å¤–å±‚æ‰§è¡Œ backfill æ—¶å¢åŠ å¯¹ panic çš„æ•è·å’Œè®°å½•ï¼Œå¦‚æœéœ€è¦æ›´å…¨é¢çš„å¤±è´¥ä»»åŠ¡åˆ—è¡¨
                    }
                }
            }
            info!(target = "backfill",log_type = "module",  "  ä»»åŠ¡ç»Ÿè®¡forå¾ªç¯çš„ç»“æŸ");
            let elapsed = start_time.elapsed();
            let total_seconds = elapsed.as_secs();
            let minutes = total_seconds / 60;
            let seconds = total_seconds % 60;

            // âœ¨ã€å»ºè®®ã€‘âœ¨ å°†ç»“æœè®°å½•åˆ°spanä¸­ï¼Œè¿™æ ·on_closeæ—¶å¯ä»¥è¯»å–åˆ°
            tracing::Span::current().record("success_count", success_count);
            tracing::Span::current().record("error_count", error_count);
            tracing::Span::current().record("elapsed_seconds", total_seconds);

            info!(target = "backfill",
                "ç¬¬ä¸€è½®Kçº¿è¡¥é½å®Œæˆï¼ŒæˆåŠŸ: {}ï¼Œå¤±è´¥: {}ï¼Œè€—æ—¶: {}åˆ†{}ç§’",
                success_count, error_count, minutes, seconds
            );

            // è¿”å›ç»Ÿè®¡ç»“æœ
            (success_count, error_count)

        }.instrument(initial_download_loop_span).await; // <-- åœ¨è¿™é‡Œ await instrument è¿‡çš„ future

        // æ£€æŸ¥å¤±è´¥ä»»åŠ¡åˆ—è¡¨å¤§å°å’Œè®¡æ•°å™¨
        let failed_tasks_size = failed_tasks.lock().await.len();
        let failed_tasks_count = failed_tasks_counter.load(std::sync::atomic::Ordering::SeqCst);
        debug!(target = "backfill", "ä»»åŠ¡å®Œæˆåï¼Œå¤±è´¥ä»»åŠ¡åˆ—è¡¨å¤§å°: {}, è®¡æ•°å™¨å€¼: {}, ç»Ÿè®¡çš„é”™è¯¯æ•°: {}",
               failed_tasks_size, failed_tasks_count, error_count);

        // å¦‚æœå­˜åœ¨ä¸ä¸€è‡´ï¼Œè®°å½•è­¦å‘Š
        if failed_tasks_size != error_count || failed_tasks_count != error_count {
            warn!(target = "backfill", "å¤±è´¥ä»»åŠ¡ç»Ÿè®¡ä¸ä¸€è‡´: åˆ—è¡¨å¤§å°={}, è®¡æ•°å™¨å€¼={}, ç»Ÿè®¡é”™è¯¯æ•°={}",
                  failed_tasks_size, failed_tasks_count, error_count);
        }

        // æ‰“å°å¤±è´¥åŸå› ç»Ÿè®¡
        let reasons = error_reasons.lock().await;

        if !reasons.is_empty() {
            info!(target: "backfill", "å¤±è´¥åŸå› ç»Ÿè®¡:");

            // å°†åŸå› æŒ‰å‡ºç°æ¬¡æ•°æ’åº
            let mut reason_counts: Vec<(String, usize)> = reasons.iter()
                .map(|(k, v)| (k.clone(), *v))
                .collect();
            reason_counts.sort_by(|a, b| b.1.cmp(&a.1));

            for (reason, count) in reason_counts {
                let percentage = (count as f64 / error_count as f64) * 100.0;
                info!(target: "backfill", "  - {}: {} æ¬¡ ({:.1}%)", reason, count, percentage);
            }
        }

        // è·å–å¤±è´¥çš„ä»»åŠ¡åˆ—è¡¨å’Œé”™è¯¯ä¿¡æ¯
        let failed_tasks_with_errors = failed_tasks.lock().await;

        // æ‰“å°æ‰€æœ‰å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯
        info!(target: "backfill", "æ‰€æœ‰å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯ (æ€»è®¡ {} ä¸ª):", failed_tasks_with_errors.len());
        info!(target: "backfill", "å¤±è´¥ä»»åŠ¡è®¡æ•°å™¨å€¼: {}, ç»Ÿè®¡çš„é”™è¯¯æ•°: {}",
              failed_tasks_counter.load(std::sync::atomic::Ordering::SeqCst), error_count);

        // è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥å¤±è´¥ä»»åŠ¡åˆ—è¡¨æ˜¯å¦ä¸ºç©º
        if failed_tasks_with_errors.is_empty() {
            error!(target: "backfill", "å¤±è´¥ä»»åŠ¡åˆ—è¡¨ä¸ºç©ºï¼Œä½†ç»Ÿè®¡æ˜¾ç¤ºæœ‰ {} ä¸ªå¤±è´¥ä»»åŠ¡", error_count);

            // å¦‚æœåˆ—è¡¨ä¸ºç©ºä½†è®¡æ•°å™¨ä¸ä¸ºé›¶ï¼Œè¯´æ˜æœ‰å¹¶å‘é—®é¢˜
            if failed_tasks_counter.load(std::sync::atomic::Ordering::SeqCst) > 0 {
                error!(target: "backfill", "æ£€æµ‹åˆ°å¹¶å‘é—®é¢˜: è®¡æ•°å™¨å€¼ä¸º {}, ä½†åˆ—è¡¨ä¸ºç©º",
                       failed_tasks_counter.load(std::sync::atomic::Ordering::SeqCst));
            }
        } else {
            debug!(target: "backfill", "å¤±è´¥ä»»åŠ¡åˆ—è¡¨ä¸­æœ‰ {} ä¸ªä»»åŠ¡", failed_tasks_with_errors.len());

            // æ‰“å°å‰5ä¸ªå¤±è´¥ä»»åŠ¡çš„ä¿¡æ¯ç”¨äºè°ƒè¯•
            for (i, (task, error_msg)) in failed_tasks_with_errors.iter().take(5).enumerate() {
                debug!(target: "backfill", "è°ƒè¯• - å¤±è´¥ä»»åŠ¡ #{}: {}/{} - é”™è¯¯: {}",
                       i+1, task.symbol, task.interval, error_msg);
            }
        }

        // æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„ç»Ÿè®¡
        let _error_type_counts: std::collections::HashMap<String, usize> = std::collections::HashMap::new();

        // è®°å½•æ¯ç§é”™è¯¯ç±»å‹çš„å‰5ä¸ªç¤ºä¾‹
        let _error_examples: std::collections::HashMap<String, Vec<(String, String, String)>> = std::collections::HashMap::new();

        // åªåœ¨æ—¥å¿—ä¸­è®°å½•å¤±è´¥ä»»åŠ¡çš„æ€»æ•°
        info!(target: "backfill", "å¤±è´¥ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ (æ€»è®¡ {} ä¸ª):", failed_tasks_with_errors.len());
        info!(target: "backfill", "{}", "=".repeat(100));

        // æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„ç»Ÿè®¡
        let mut error_type_counts: std::collections::HashMap<String, usize> = std::collections::HashMap::new();

        // è®°å½•æ¯ç§é”™è¯¯ç±»å‹çš„å‰5ä¸ªç¤ºä¾‹
        let mut error_examples: std::collections::HashMap<String, Vec<(String, String, String)>> = std::collections::HashMap::new();

        for (i, (task, error_msg)) in failed_tasks_with_errors.iter().enumerate() {
            // æå–é”™è¯¯ç±»å‹
            let error_type = if error_msg.contains("HTTP error") {
                "HTTP error"
            } else if error_msg.contains("timeout") {
                "è¯·æ±‚è¶…æ—¶"
            } else if error_msg.contains("429 Too Many Requests") {
                "429 Too Many Requests"
            } else if error_msg.contains("ç©ºç»“æœ") {
                "ç©ºç»“æœ"
            } else if error_msg.contains("unexpected EOF during handshake") {
                "æ¡æ‰‹ä¸­æ–­"
            } else {
                // æå–é”™è¯¯ç±»å‹çš„ç¬¬ä¸€éƒ¨åˆ†
                let parts: Vec<&str> = error_msg.split(':').collect();
                if parts.len() > 1 {
                    parts[0].trim()
                } else {
                    "å…¶ä»–é”™è¯¯"
                }
            };

            // æ›´æ–°é”™è¯¯ç±»å‹è®¡æ•°
            *error_type_counts.entry(error_type.to_string()).or_insert(0) += 1;

            // ä¸ºæ¯ç§é”™è¯¯ç±»å‹ä¿å­˜æœ€å¤š5ä¸ªç¤ºä¾‹
            if let Some(examples) = error_examples.get_mut(error_type) {
                if examples.len() < 5 {
                    examples.push((task.symbol.clone(), task.interval.clone(), error_msg.clone()));
                }
            } else {
                error_examples.insert(error_type.to_string(), vec![(task.symbol.clone(), task.interval.clone(), error_msg.clone())]);
            }

            // æ„å»ºURLå‚æ•°ç”¨äºæ—¥å¿—è®°å½•
            let mut url_params = format!(
                "symbol={}&interval={}&limit={}",
                task.symbol, task.interval, task.limit
            );

            // æ·»åŠ å¯é€‰çš„èµ·å§‹æ—¶é—´
            if let Some(start_time) = task.start_time {
                url_params.push_str(&format!("&startTime={}", start_time));
            }

            // æ·»åŠ å¯é€‰çš„ç»“æŸæ—¶é—´
            if let Some(end_time) = task.end_time {
                url_params.push_str(&format!("&endTime={}", end_time));
            }

            // æ„å»ºå®Œæ•´URL
            let fapi_url = format!("https://fapi.binance.com/fapi/v1/klines?{}", url_params);

            // ä¸å†å†™å…¥é”™è¯¯æ—¥å¿—æ–‡ä»¶ï¼Œåªåœ¨æ§åˆ¶å°æ‰“å°è¯¦ç»†ä¿¡æ¯

            // æ¯10ä¸ªé”™è¯¯åœ¨æ§åˆ¶å°æ‰“å°ä¸€ä¸ªè¯¦ç»†ç¤ºä¾‹
            if i < 10 || i % 100 == 0 {
                info!(target: "backfill", "å¤±è´¥ä»»åŠ¡ #{}: {}/{} - {}", i+1, task.symbol, task.interval, error_type);
                info!(target: "backfill", "  é”™è¯¯ä¿¡æ¯: {}", error_msg);
                info!(target: "backfill", "  è¯·æ±‚URL: {}", fapi_url);
            }

            // æ¯100ä¸ªé”™è¯¯æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (i + 1) % 100 == 0 || i == failed_tasks_with_errors.len() - 1 {
                info!(target: "backfill", "å·²å¤„ç† {}/{} ä¸ªå¤±è´¥ä»»åŠ¡", i + 1, failed_tasks_with_errors.len());
            };
        }

        info!(target: "backfill", "æ‰€æœ‰å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯å·²è®°å½•åˆ°ä¸»æ—¥å¿—æ–‡ä»¶");

        // æ‰“å°é”™è¯¯ç±»å‹ç»Ÿè®¡
        info!(target: "backfill", "å¤±è´¥ä»»åŠ¡æŒ‰é”™è¯¯ç±»å‹ç»Ÿè®¡:");
        let mut sorted_error_types: Vec<(String, usize)> = error_type_counts.into_iter().collect();
        sorted_error_types.sort_by(|a, b| b.1.cmp(&a.1)); // æŒ‰æ•°é‡é™åºæ’åº

        for (error_type, count) in &sorted_error_types {
            let percentage = (count * 100) as f64 / failed_tasks_with_errors.len() as f64;
            info!(target: "backfill", "  - {}: {} ä¸ªä»»åŠ¡ ({:.1}%)", error_type, count, percentage);

            // æ‰“å°è¯¥é”™è¯¯ç±»å‹çš„ç¤ºä¾‹
            if let Some(examples) = error_examples.get(error_type) {
                info!(target: "backfill", "    ç¤ºä¾‹:");
                for (idx, (symbol, interval, error)) in examples.iter().enumerate() {
                    info!(target: "backfill", "    {}) {}/{}: {}", idx + 1, symbol, interval, error);
                }
            }
        }

        // å®šä¹‰éœ€è¦é‡è¯•çš„é”™è¯¯å…³é”®è¯ï¼Œè¿™æ ·åšæ›´å¥å£®ï¼Œä¸å®¹æ˜“å‡ºé”™
        let retry_keywords = vec![
            "HTTP error",
            "timeout",           // ç›´æ¥æ£€æŸ¥å…³é”®è¯ï¼Œæ•è·å„ç§è¶…æ—¶é”™è¯¯
            "429",              // ç›´æ¥æ£€æŸ¥çŠ¶æ€ç 
            "Too Many Requests",
            "handshake",        // æ•è· "unexpected EOF during handshake"
            "connection",       // æ•è·è¿æ¥ç›¸å…³é”™è¯¯
            "network",          // æ•è·ç½‘ç»œç›¸å…³é”™è¯¯
        ];

        info!(target: "backfill", "å°†é‡è¯•åŒ…å«ä»¥ä¸‹å…³é”®è¯çš„é”™è¯¯: {:?}", retry_keywords);

        // è·å–éœ€è¦é‡è¯•çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆæ ¹æ®é”™è¯¯å…³é”®è¯è¿‡æ»¤ï¼‰
        let retry_tasks: Vec<DownloadTask> = failed_tasks_with_errors
            .iter()
            .filter(|(_, error_msg)| {
                // åªè¦é”™è¯¯ä¿¡æ¯åŒ…å«ä»»æ„ä¸€ä¸ªé‡è¯•å…³é”®è¯ï¼Œå°±è¿›è¡Œé‡è¯•
                retry_keywords.iter().any(|keyword| error_msg.contains(keyword))
            })
            .map(|(task, _)| task.clone())
            .collect();

        // å¦‚æœæœ‰éœ€è¦é‡è¯•çš„ä»»åŠ¡ï¼Œè¿›è¡Œé‡è¯•
        if !retry_tasks.is_empty() {
            info!(target: "backfill", "å¼€å§‹é‡è¯• {} ä¸ªå¤±è´¥çš„ä¸‹è½½ä»»åŠ¡...", retry_tasks.len());

            // âœ¨ã€å¿…é¡»çš„ä¿®æ”¹ã€‘âœ¨ 2. åŒ…è£¹ç¬¬äºŒè½®é‡è¯•å¾ªç¯
            let retry_loop_span = tracing::info_span!(
                "retry_download_loop", // åŒæ ·ä½¿ç”¨ `_loop` åç¼€
                target = "backfill",
                task_count = retry_tasks.len(),
                concurrency = 50,
                iterator_type = "RetryTask"
            );

            async {
                let retry_start_time = Instant::now();
                let mut retry_handles = Vec::new();
                let retry_failed_tasks = Arc::new(tokio::sync::Mutex::new(Vec::new()));
                let retry_error_reasons = Arc::new(tokio::sync::Mutex::new(std::collections::HashMap::new()));
                let retry_semaphore = Arc::new(tokio::sync::Semaphore::new(50)); // é‡è¯•ä½¿ç”¨50ä¸ªå¹¶å‘ï¼Œå……åˆ†åˆ©ç”¨ç½‘ç»œå¸¦å®½ï¼Œå†™å…¥æ“ä½œç”±DbWriteQueueåºåˆ—åŒ–å¤„ç†
                let total_retry_tasks = retry_tasks.len();

                info!(target: "backfill", log_type = "module",
                    "å¼€å§‹é‡è¯•ä»»åŠ¡åˆ›å»ºå¾ªç¯ - é‡è¯•ä»»åŠ¡æ•°: {}, å¹¶å‘æ•°: 50, é¢„æœŸæˆåŠŸç‡: >80%",
                    total_retry_tasks
                );

                for (retry_index, task) in retry_tasks.into_iter().enumerate() {
                    let api_clone = self.api.clone();
                    let semaphore_clone = retry_semaphore.clone();
                    let db_clone = self.db.clone();
                    let retry_failed_tasks_clone = retry_failed_tasks.clone();
                    let retry_error_reasons_clone = retry_error_reasons.clone();
                    let task_clone = task.clone();

                    let _symbol = task.symbol.clone();
                    let _interval = task.interval.clone();

                    // âœ¨ã€å…³é”®ä¿®å¤ã€‘âœ¨ å…ˆå®šä¹‰futureï¼Œå°†spanåˆ›å»ºç§»åŠ¨åˆ°è·å–è®¸å¯ä¹‹å
                    let retry_future = async move {
                        // è·å–ä¿¡å·é‡è®¸å¯
                        let _permit = semaphore_clone.acquire().await.unwrap();

                        let symbol = task.symbol.clone();
                        let interval = task.interval.clone();

                        // âœ¨ã€å…³é”®ä¿®å¤ã€‘âœ¨ åœ¨è¿™é‡Œåˆ›å»ºspanï¼Œå®ƒåªåŒ…è£¹çœŸæ­£çš„é‡è¯•å·¥ä½œ
                        let retry_task_span = tracing::info_span!(
                            "retry_download_task", // ä¸å†éœ€è¦ "_sample" åç¼€
                            symbol = %symbol,
                            interval = %interval,
                            target = "backfill",
                            retry_index = retry_index
                        );

                    async move {
                        // è®°å½•APIè¯·æ±‚
                        let request_id = API_REQUEST_STATS.0.fetch_add(1, Ordering::SeqCst);
                        // ä¸å†è®°å½•å¼€å§‹è¯·æ±‚çš„æ—¥å¿—

                        // æ„å»ºURLå‚æ•°
                        let mut url_params = format!(
                            "symbol={}&interval={}&limit={}",
                            task.symbol, task.interval, task.limit
                        );

                        // æ·»åŠ å¯é€‰çš„èµ·å§‹æ—¶é—´
                        if let Some(start_time) = task.start_time {
                            url_params.push_str(&format!("&startTime={}", start_time));
                        }

                        // æ·»åŠ å¯é€‰çš„ç»“æŸæ—¶é—´
                        if let Some(end_time) = task.end_time {
                            url_params.push_str(&format!("&endTime={}", end_time));
                        }

                        // æ„å»ºå®Œæ•´URL
                        let fapi_url = format!("https://fapi.binance.com/fapi/v1/klines?{}", url_params);
                        // ä¸å†è®°å½•URLæ—¥å¿—ï¼Œåªåœ¨å¤±è´¥æ—¶è®°å½•

                        // ä¸‹è½½ä»»åŠ¡
                        match api_clone.download_continuous_klines(&task).await {
                            Ok(klines) => {
                                // æ›´æ–°æˆåŠŸè¯·æ±‚è®¡æ•°
                                API_REQUEST_STATS.1.fetch_add(1, Ordering::SeqCst);
                                // ä¸å†è®°å½•æˆåŠŸè¯·æ±‚çš„æ—¥å¿—

                                if klines.is_empty() {
                                    // è®°å½•ç©ºç»“æœé”™è¯¯
                                    let error_msg = "ç©ºç»“æœ".to_string();
                                    error!(target: "backfill", "{}/{}: é‡è¯•ä¸‹è½½å¤±è´¥: {}", symbol, interval, error_msg);

                                    // æ›´æ–°é”™è¯¯ç»Ÿè®¡
                                    {
                                        let mut reasons = retry_error_reasons_clone.lock().await;
                                        *reasons.entry(error_msg.clone()).or_insert(0) += 1;
                                    }

                                    // å°†å¤±è´¥çš„ä»»åŠ¡å’ŒåŸå› æ·»åŠ åˆ°å¤±è´¥åˆ—è¡¨ä¸­
                                    retry_failed_tasks_clone.lock().await.push((task_clone, error_msg));
                                    return Err(AppError::DataError("ç©ºç»“æœ".to_string()));
                                }

                                // æŒ‰æ—¶é—´æ’åº
                                let mut sorted_klines = klines.clone();
                                sorted_klines.sort_by_key(|k| k.open_time);

                                // ä¿å­˜åˆ°æ•°æ®åº“ (å¼‚æ­¥)
                                let count = db_clone.save_klines(&symbol, &interval, &sorted_klines).await?;

                                // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                                Self::update_backfill_stats(&symbol, &interval, count);

                                Ok(())
                            }
                            Err(e) => {
                                // æ›´æ–°å¤±è´¥è¯·æ±‚è®¡æ•°
                                API_REQUEST_STATS.2.fetch_add(1, Ordering::SeqCst);

                                let error_msg = format!("{}", e);
                                error!(target: "backfill", "é‡è¯•APIè¯·æ±‚ #{}: {}/{} - è¯·æ±‚å¤±è´¥: {}",
                                       request_id, symbol, interval, error_msg);
                                error!(target: "backfill", "{}/{}: é‡è¯•ä¸‹è½½å¤±è´¥: {}", symbol, interval, error_msg);
                                error!(target: "backfill", "å¤±è´¥çš„URL: {}", fapi_url);

                                // æ›´æ–°é”™è¯¯ç»Ÿè®¡
                                {
                                    let mut reasons = retry_error_reasons_clone.lock().await;
                                    let reason_key = if error_msg.contains("429 Too Many Requests") {
                                        "429 Too Many Requests".to_string()
                                    } else if error_msg.contains("timeout") {
                                        "è¯·æ±‚è¶…æ—¶".to_string()
                                    } else if error_msg.contains("unexpected EOF during handshake") {
                                        "æ¡æ‰‹ä¸­æ–­".to_string()
                                    } else if error_msg.contains("HTTP error") {
                                        "HTTP error".to_string()
                                    } else if error_msg.contains("empty response") {
                                        "ç©ºå“åº”".to_string()
                                    } else {
                                        // æå–é”™è¯¯ç±»å‹
                                        let parts: Vec<&str> = error_msg.split(':').collect();
                                        if parts.len() > 1 {
                                            parts[0].trim().to_string()
                                        } else {
                                            error_msg.clone()
                                        }
                                    };
                                    *reasons.entry(reason_key).or_insert(0) += 1;
                                }

                                // å°†å¤±è´¥çš„ä»»åŠ¡å’ŒåŸå› æ·»åŠ åˆ°å¤±è´¥åˆ—è¡¨ä¸­
                                retry_failed_tasks_clone.lock().await.push((task_clone, format!("URL={}, é”™è¯¯: {}", fapi_url, error_msg)));
                                Err(e)
                            }
                        }
                    }.instrument(retry_task_span).await // instrument å¹¶ await
                };

                    // âœ¨ã€æœ€ç»ˆä¿®å¤ã€‘âœ¨ å¯¹é‡è¯•ä»»åŠ¡ä¹Ÿåº”ç”¨ç›¸åŒçš„ instrument é€»è¾‘
                    let instrumented_retry_future = retry_future.instrument(tracing::Span::current());
                    let handle = tokio::spawn(instrumented_retry_future);
                    retry_handles.push(handle);
                }

                // ç­‰å¾…æ‰€æœ‰é‡è¯•ä»»åŠ¡å®Œæˆ
                let mut retry_success_count = 0;
                let mut retry_error_count = 0;
                let total_retry_handles = retry_handles.len();

                info!(target: "backfill", log_type = "module",
                    "å¼€å§‹ç­‰å¾…é‡è¯•ä»»åŠ¡å®Œæˆå¾ªç¯ - æ€»é‡è¯•ä»»åŠ¡æ•°: {}, å¹¶å‘æ•°: 50, é¢„æœŸæˆåŠŸç‡: >80%",
                    total_retry_handles
                );

                for handle in retry_handles {
                    match handle.await {
                        Ok(result) => {
                            match result {
                                Ok(_) => retry_success_count += 1,
                                Err(_) => retry_error_count += 1,
                            }
                        }
                        Err(e) => {
                            error!(target: "backfill", "é‡è¯•ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {}", e);
                            retry_error_count += 1;
                        }
                    }
                }

                let retry_elapsed = retry_start_time.elapsed();
                let final_failed_tasks = retry_failed_tasks.lock().await.len();
                let total_seconds = retry_elapsed.as_secs();
                let minutes = total_seconds / 60;
                let seconds = total_seconds % 60;

                // âœ¨ã€å»ºè®®ã€‘âœ¨ è®°å½•ç»Ÿè®¡ç»“æœåˆ°spanï¼ŒåŒ…æ‹¬æ›´å¤šæœ‰ç”¨çš„ä¿¡æ¯
                tracing::Span::current().record("success_count", retry_success_count);
                tracing::Span::current().record("error_count", retry_error_count);
                tracing::Span::current().record("final_failed_count", final_failed_tasks);
                tracing::Span::current().record("elapsed_seconds", total_seconds);

                info!(target: "backfill",
                    "é‡è¯•ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ: {}ï¼Œå¤±è´¥: {}ï¼Œæœ€ç»ˆå¤±è´¥: {}ï¼Œè€—æ—¶: {}åˆ†{}ç§’",
                    retry_success_count, retry_error_count, final_failed_tasks, minutes, seconds
                );

            // æ‰“å°é‡è¯•å¤±è´¥åŸå› ç»Ÿè®¡
            let retry_reasons = retry_error_reasons.lock().await;
            if !retry_reasons.is_empty() {
                info!(target: "backfill", "é‡è¯•å¤±è´¥åŸå› ç»Ÿè®¡:");

                // å°†åŸå› æŒ‰å‡ºç°æ¬¡æ•°æ’åº
                let mut reason_counts: Vec<(String, usize)> = retry_reasons.iter()
                    .map(|(k, v)| (k.clone(), *v))
                    .collect();
                reason_counts.sort_by(|a, b| b.1.cmp(&a.1));

                for (reason, count) in reason_counts {
                    let percentage = (count as f64 / retry_error_count as f64) * 100.0;
                    info!(target: "backfill", "  - {}: {} æ¬¡ ({:.1}%)", reason, count, percentage);
                }
            }

            // å¦‚æœæœ‰æœ€ç»ˆå¤±è´¥çš„ä»»åŠ¡ï¼Œæ‰“å°æ‰€æœ‰å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
            if final_failed_tasks > 0 {
                let final_failed = retry_failed_tasks.lock().await;
                info!(target: "backfill", "æ‰€æœ‰æœ€ç»ˆå¤±è´¥ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå…± {} ä¸ªï¼‰:", final_failed.len());

                // æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
                let mut error_type_groups = std::collections::HashMap::new();

                // åªåœ¨æ—¥å¿—ä¸­è®°å½•é‡è¯•å¤±è´¥ä»»åŠ¡çš„æ€»æ•°
                info!(target: "backfill", "é‡è¯•å¤±è´¥ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ (æ€»è®¡ {} ä¸ª):", final_failed.len());
                info!(target: "backfill", "{}", "=".repeat(100));

                for (i, (task, reason)) in final_failed.iter().enumerate() {
                    // æå–é”™è¯¯ç±»å‹
                    let error_type = if reason.contains("429 Too Many Requests") {
                        "429 Too Many Requests"
                    } else if reason.contains("timeout") {
                        "è¯·æ±‚è¶…æ—¶"
                    } else if reason.contains("unexpected EOF during handshake") {
                        "æ¡æ‰‹ä¸­æ–­"
                    } else if reason.contains("HTTP error") {
                        "HTTP error"
                    } else if reason.contains("ç©ºç»“æœ") {
                        "ç©ºç»“æœ"
                    } else {
                        "å…¶ä»–é”™è¯¯"
                    };

                    error_type_groups
                        .entry(error_type.to_string())
                        .or_insert_with(Vec::new)
                        .push((task.clone(), reason.clone()));

                    // æ„å»ºURLå‚æ•°ç”¨äºæ—¥å¿—è®°å½•
                    let mut url_params = format!(
                        "symbol={}&interval={}&limit={}",
                        task.symbol, task.interval, task.limit
                    );

                    // æ·»åŠ å¯é€‰çš„èµ·å§‹æ—¶é—´
                    if let Some(start_time) = task.start_time {
                        url_params.push_str(&format!("&startTime={}", start_time));
                    }

                    // æ·»åŠ å¯é€‰çš„ç»“æŸæ—¶é—´
                    if let Some(end_time) = task.end_time {
                        url_params.push_str(&format!("&endTime={}", end_time));
                    }

                    // æ„å»ºå®Œæ•´URL
                    let fapi_url = format!("https://fapi.binance.com/fapi/v1/klines?{}", url_params);

                    // ä¸å†å†™å…¥é”™è¯¯æ—¥å¿—æ–‡ä»¶ï¼Œåªåœ¨æ§åˆ¶å°æ‰“å°è¯¦ç»†ä¿¡æ¯

                    // æ¯10ä¸ªé”™è¯¯åœ¨æ§åˆ¶å°æ‰“å°ä¸€ä¸ªè¯¦ç»†ç¤ºä¾‹
                    if i < 10 || i % 100 == 0 {
                        info!(target: "backfill", "é‡è¯•å¤±è´¥ä»»åŠ¡ #{}: {}/{} - {}", i+1, task.symbol, task.interval, error_type);
                        info!(target: "backfill", "  é”™è¯¯ä¿¡æ¯: {}", reason);
                        info!(target: "backfill", "  è¯·æ±‚URL: {}", fapi_url);
                    }
                }

                info!(target: "backfill", "æ‰€æœ‰é‡è¯•å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯å·²è®°å½•åˆ°ä¸»æ—¥å¿—æ–‡ä»¶");

                // æŒ‰é”™è¯¯ç±»å‹æ˜¾ç¤º
                for (error_type, tasks) in &error_type_groups {
                    info!(target: "backfill", "\né”™è¯¯ç±»å‹: {} - {} ä¸ªä»»åŠ¡", error_type, tasks.len());

                    // åªæ˜¾ç¤ºæ¯ç§ç±»å‹çš„å‰5ä¸ªç¤ºä¾‹
                    for (i, (task, reason)) in tasks.iter().take(5).enumerate() {
                        info!(target: "backfill", "  {}. {}/{}: {}", i+1, task.symbol, task.interval, reason);
                    }

                    // å¦‚æœæœ‰æ›´å¤šï¼Œæ˜¾ç¤ºå‰©ä½™æ•°é‡
                    if tasks.len() > 5 {
                        info!(target: "backfill", "  ... ä»¥åŠå…¶ä»– {} ä¸ªä»»åŠ¡", tasks.len() - 5);
                    }
                }
            }

            }.instrument(retry_loop_span).await; // <-- await instrument è¿‡çš„ future
        }

        let total_elapsed = start_time.elapsed();
        let total_seconds = total_elapsed.as_secs();
        let hours = total_seconds / 3600;
        let minutes = (total_seconds % 3600) / 60;
        let seconds = total_seconds % 60;

        // è·å–APIè¯·æ±‚ç»Ÿè®¡
        let total_requests = API_REQUEST_STATS.0.load(Ordering::SeqCst);
        let successful_requests = API_REQUEST_STATS.1.load(Ordering::SeqCst);
        let failed_requests = API_REQUEST_STATS.2.load(Ordering::SeqCst);

        info!(target: "backfill", "APIè¯·æ±‚ç»Ÿè®¡: æ€»è®¡å‘é€ {} ä¸ªè¯·æ±‚ï¼ŒæˆåŠŸ {} ä¸ªï¼Œå¤±è´¥ {} ä¸ª",
            total_requests, successful_requests, failed_requests
        );

        // è·å–æ€»è®¡è¡¥é½çš„Kçº¿æ•°é‡
        let total_klines = BACKFILL_STATS.0.load(Ordering::Relaxed);

        info!(target: "backfill",
            "Kçº¿è¡¥é½å…¨éƒ¨å®Œæˆï¼Œæ€»è®¡: {} æ¡Kçº¿ï¼Œæ€»è€—æ—¶: {}å°æ—¶{}åˆ†{}ç§’",
            total_klines, hours, minutes, seconds
        );

        // æ—¶é—´æˆ³æ£€æŸ¥åŠŸèƒ½å·²ç§»è‡³ timestamp_checker.rsï¼Œæµ‹è¯•å·²é€šè¿‡ï¼Œæ­¤å¤„å±è”½
        // let timestamp_checker = crate::kldata::TimestampChecker::new(self.db.clone(), self.intervals.clone());
        // timestamp_checker.check_last_kline_consistency().await?;
        info!(target: "backfill", "æ—¶é—´æˆ³æ£€æŸ¥åŠŸèƒ½å·²ç§»è‡³ timestamp_checker.rsï¼Œæµ‹è¯•å·²é€šè¿‡ï¼Œæ­¤å¤„å±è”½");

        Ok(())
    }

    // æ—¶é—´æˆ³æ£€æŸ¥ç›¸å…³æ–¹æ³•å·²ç§»è‡³ timestamp_checker.rs

    // æ—¶é—´æˆ³è½¬æ¢æ–¹æ³•å·²ç§»è‡³ timestamp_checker.rs

    /// è·å–æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„Kçº¿è¡¨
    fn get_existing_kline_tables(&self) -> Result<Vec<(String, String)>> {
        let conn = self.db.get_connection()?;
        let mut tables = Vec::new();

        // æŸ¥è¯¢æ‰€æœ‰ä»¥k_å¼€å¤´çš„è¡¨
        let query = "SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'k_%'";
        let mut stmt = conn.prepare(query)?;
        let rows = stmt.query_map([], |row| row.get::<_, String>(0))?;

        // è§£æè¡¨åï¼Œæå–å“ç§å’Œå‘¨æœŸ
        for row in rows {
            let table_name = row?;
            if let Some((symbol, interval)) = self.parse_table_name(&table_name) {
                // åªå¤„ç†æŒ‡å®šçš„å‘¨æœŸ
                if self.intervals.contains(&interval) {
                    tables.push((symbol, interval));
                }
            }
        }

        Ok(tables)
    }

    /// è§£æè¡¨åï¼Œæå–å“ç§å’Œå‘¨æœŸ
    fn parse_table_name(&self, table_name: &str) -> Option<(String, String)> {
        let parts: Vec<&str> = table_name.split('_').collect();

        if parts.len() >= 3 {
            let symbol = format!("{}USDT", parts[1].to_uppercase()); // æ·»åŠ USDTåç¼€
            let interval = parts[2].to_string();
            return Some((symbol, interval));
        }

        None
    }

    /// é¢„å…ˆåˆ›å»ºæ‰€æœ‰éœ€è¦çš„è¡¨
    fn ensure_all_tables(&self, symbols: &[String]) -> Result<()> {
        info!(target: "backfill", "å¼€å§‹é¢„å…ˆåˆ›å»ºæ‰€æœ‰éœ€è¦çš„è¡¨ï¼Œå…± {} ä¸ªäº¤æ˜“å¯¹ï¼Œæ¯ä¸ª {} ä¸ªå‘¨æœŸ",
              symbols.len(), self.intervals.len());

        let mut created_count = 0;
        let mut existing_count = 0;

        // è·å–å·²å­˜åœ¨çš„è¡¨
        let existing_tables = self.get_existing_kline_tables()?;
        let mut existing_map = HashMap::new();

        for (symbol, interval) in existing_tables {
            existing_map.insert((symbol, interval), true);
        }

        // ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹å’Œå‘¨æœŸåˆ›å»ºè¡¨
        for symbol in symbols {
            for interval in &self.intervals {
                // æ£€æŸ¥è¡¨æ˜¯å¦å·²å­˜åœ¨
                if existing_map.contains_key(&(symbol.clone(), interval.clone())) {
                    existing_count += 1;
                    continue;
                }

                // åˆ›å»ºè¡¨
                self.db.ensure_symbol_table(symbol, interval)?;
                created_count += 1;

                // æ¯åˆ›å»º10ä¸ªè¡¨è¾“å‡ºä¸€æ¬¡æ—¥å¿—
                if created_count % 10 == 0 {
                    //debug!("å·²åˆ›å»º {} ä¸ªè¡¨ï¼Œè·³è¿‡ {} ä¸ªå·²å­˜åœ¨çš„è¡¨", created_count, existing_count);
                }
            }
        }

        info!(target: "backfill", "è¡¨åˆ›å»ºå®Œæˆï¼Œæ–°åˆ›å»º {} ä¸ªè¡¨ï¼Œè·³è¿‡ {} ä¸ªå·²å­˜åœ¨çš„è¡¨", created_count, existing_count);
        Ok(())
    }

    /// åˆ›å»ºæ‰€æœ‰ä¸‹è½½ä»»åŠ¡çš„ä¸»å‡½æ•°
    /// æ³¨æ„ï¼šç§»é™¤äº†#[instrument]æ³¨è§£ï¼Œå› ä¸ºå·²è¢«å¤–éƒ¨çš„task_creation_loop spanè¿½è¸ª
    async fn create_all_download_tasks(&self, all_symbols: &[String]) -> Result<Vec<DownloadTask>> {
        let mut tasks = Vec::new();

        // è·å–æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„è¡¨ä¿¡æ¯
        let existing_tables = self.get_existing_kline_tables()?;
        let mut existing_symbol_intervals = HashMap::new();

        for (symbol, interval) in &existing_tables {
            existing_symbol_intervals
                .entry(symbol.clone())
                .or_insert_with(Vec::new)
                .push(interval.clone());
        }

        // ä¸ºæ–°å“ç§åˆ›å»ºå®Œæ•´ä¸‹è½½ä»»åŠ¡ï¼ˆå…ˆè®¡ç®—ï¼Œé¿å…å€Ÿç”¨å†²çªï¼‰
        let new_symbols: Vec<String> = all_symbols.iter()
            .filter(|symbol| !existing_symbol_intervals.contains_key(*symbol))
            .cloned()
            .collect();

        // ä¸ºå·²å­˜åœ¨çš„å“ç§åˆ›å»ºè¡¥é½ä»»åŠ¡
        for (symbol, intervals) in existing_symbol_intervals {
            if !all_symbols.contains(&symbol) {
                continue;
            }
            for interval in intervals {
                if let Some(task) = self.create_task_for_existing_symbol(&symbol, &interval).await? {
                    tasks.push(task);
                }
            }
        }

        for symbol in new_symbols {
            for interval in &self.intervals {
                let task = self.create_task_for_new_symbol(&symbol, interval).await?;
                tasks.push(task);
            }
        }

        Ok(tasks)
    }

    /// ä¸ºå·²å­˜åœ¨çš„äº¤æ˜“å¯¹åˆ›å»ºè¡¥é½ä»»åŠ¡
    #[instrument(skip(self), ret, err)]
    async fn create_task_for_existing_symbol(&self, symbol: &str, interval: &str) -> Result<Option<DownloadTask>> {
        let current_time = chrono::Utc::now().timestamp_millis();

        if let Some(last_timestamp) = self.db.get_latest_kline_timestamp(symbol, interval)? {
            // æœ‰æ•°æ®çš„æƒ…å†µï¼šåˆ›å»ºè¡¥é½ä»»åŠ¡
            let interval_ms = crate::klcommon::api::interval_to_milliseconds(interval);
            let start_time = last_timestamp + interval_ms;

            let aligned_start_time = get_aligned_time(start_time, interval);
            let aligned_end_time = get_aligned_time(current_time, interval);

            if aligned_start_time < aligned_end_time {
                Ok(Some(DownloadTask {
                    symbol: symbol.to_string(),
                    interval: interval.to_string(),
                    start_time: Some(aligned_start_time),
                    end_time: Some(aligned_end_time),
                    limit: 1000,
                }))
            } else {
                Ok(None) // ä¸éœ€è¦è¡¥é½
            }
        } else {
            // è¡¨å­˜åœ¨ä½†æ— æ•°æ®ï¼šåˆ›å»ºå®Œæ•´ä¸‹è½½ä»»åŠ¡
            let start_time = self.calculate_historical_start_time(current_time, interval);
            let aligned_start_time = get_aligned_time(start_time, interval);
            let aligned_end_time = get_aligned_time(current_time, interval);

            Ok(Some(DownloadTask {
                symbol: symbol.to_string(),
                interval: interval.to_string(),
                start_time: Some(aligned_start_time),
                end_time: Some(aligned_end_time),
                limit: 1000,
            }))
        }
    }

    /// ä¸ºæ–°å“ç§åˆ›å»ºå®Œæ•´ä¸‹è½½ä»»åŠ¡
    #[instrument(skip(self), ret, err)]
    async fn create_task_for_new_symbol(&self, symbol: &str, interval: &str) -> Result<DownloadTask> {
        let current_time = chrono::Utc::now().timestamp_millis();
        let start_time = self.calculate_historical_start_time(current_time, interval);

        let aligned_start_time = get_aligned_time(start_time, interval);
        let aligned_end_time = get_aligned_time(current_time, interval);

        Ok(DownloadTask {
            symbol: symbol.to_string(),
            interval: interval.to_string(),
            start_time: Some(aligned_start_time),
            end_time: Some(aligned_end_time),
            limit: 1000,
        })
    }

    /// æ ¹æ®å‘¨æœŸè®¡ç®—å†å²æ•°æ®çš„èµ·å§‹æ—¶é—´
    fn calculate_historical_start_time(&self, current_time: i64, interval: &str) -> i64 {
        match interval {
            "1m" => current_time - 1000 * 60 * 1000, // 1000åˆ†é’Ÿ
            "5m" => current_time - 5000 * 60 * 1000, // 5000åˆ†é’Ÿ
            "30m" => current_time - 30000 * 60 * 1000, // 30000åˆ†é’Ÿ
            "1h" => current_time - 1000 * 60 * 60 * 1000, // 1000å°æ—¶
            "4h" => current_time - 4 * 1000 * 60 * 60 * 1000, // 4000å°æ—¶
            "1d" => current_time - 1000 * 24 * 60 * 60 * 1000, // 1000å¤©
            "1w" => current_time - 200 * 7 * 24 * 60 * 60 * 1000, // 200å‘¨
            _ => current_time - 1000 * 60 * 1000, // é»˜è®¤1000åˆ†é’Ÿ
        }
    }
}
