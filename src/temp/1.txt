`src\bin\kline_aggregate_service.rs`是老版本的k线聚合入口`src\klaggregate`中的代码是老版本的k线聚合实现
`src\klcommon\api.rs`是公共api实现
`src\klcommon\db.rs`是公共数据库实现
`src\klcommon\server_time_sync.rs`和币安服务器校时
`src\klcommon\websocket.rs`币安合约websocket的实现
`src\bin\klagg_simple.rs`是新版k线聚合的入口文件
`src\klagg_simple\mod.rs`新版k线聚合的实现文件`src\klagg_simple\types.rs`新版K线聚合数据结构文件
新版的目标是使用流程简洁，数据流程简洁的紧凑代码，但目前功能还有缺失，而老版是接近完成的代码
我们来一步一步，根据老版本，完善新版本
你首先分析老版本的功能，然后分析新版本的功能，然后对比，提出质疑，或者觉得我需要澄清的地方
我先表述一遍主要数据流程，有助于你理解
1 调用api.rs中的获取合约列表的api
2 将这些品种，分成5等份，使用5个websocket连接到币安（目的是为了降低处理websocket信息模块的压力）
3 每个品种，初始化一个actor，每个actor都是处理固定品种，不会改变
4 有一个类似路由器的东西，比如btcusdt收到了一个新数据，那么就发送给btcusdt的actor
5 btcusdt的actor内部收到高频数据之后，合成出最新的7个周期的K线（硬编码的周期），actor之间并没有消息传递（mpsc::unbounded_channel）进行通信，actor之间，不需要通信
6 然后有一个双缓冲的扁平数组，这个扁平数组是解决actor中生成的最新K线数据如何被外部并发读的问题，会在程序开始的时候初始化，首先新建两个10000长度的一维数组（为了应对币安的品种增加，不用扩容），然后从数据库中读取每个品种，最早的日线级K线的开始时间，进行排序，目的是为了固定品种在扁平数组上位置，比如btcusdt是最早的品种，那么数组的第0到第六，就是btcusdt的7个周期的K线存储的位置，第二早的是ethusdt，就占据了第7到第13，以此类推，由于位置是固定的，所以每个品种的actor合成完数据之后，不存在并发写的问题，因为位置和品种是一一对应的，然后有两个扁平数组，靠一个原子操作，切换读写缓冲区，这里面的1秒钟切换一次太低了，生产环境是100ms一次，这是常规操作，你应该懂的，这里并没有
7，靠第六步，就可以实现外部可以非常高频的读取合成完的K线数据，到这里主体功能就完成了，剩下的就是写入到数据库了

你需要分析新版本实现功能的完备性，以及代码是否紧凑，数据处理是否紧凑，是否有不必要的抽象导致的冗余代码
日志系统，不用考虑，先实现基础功能
动态添加系统不用考虑，先实现基础功能

注意实现代码，尽量使用过程式，不要java式的，某某处理器，处理某某对象，这样会造成大量冗余代码，目前的实现都过程式处理数据，非常紧凑
需要输出新版本代码时，注意每次都是全部输出，因为代码量很少

我来描述下整个过程
1 获得交易品种，比如500个
2 获得交易品种的最早的1根日线的open time，也就是上币时间，进行排序，天然的固定排序
3 初始化4个线程对应4个物理线程，通过一个品种分配器，将品种固定在线程上，每次计算都尽量命中缓存
4 有一个数据结构，记录的是，每个品种的（配置好的7个周期）未完成的K线，位置index使用第二步的上币时间，但这块我没台想清楚，你帮我想想，大概是通过字符串查询‘btcusdt’的index是 第0位，然后根据这个index，去一个长数组上，顺序的找到7个合成中的k线数据，也就是从0到6相对应的，查找ethusdt，的index是第1位，根据index=1，去长数组上，顺序的找到，也就是从7到13

5 我想清楚了，你看actor的版本中有双缓冲扁平数组，根据新的高频数据，聚合后的最新K线数据，那么就需要一个保存k线合成状态的数组，就是：上次k线数据+这次高频数据=最新k线数据，最新k线数据的扁平数组和上次k线数据是一样的，都是扁平数组，index都是一样的

1 我已经实现了actor版本的k线聚合，但问题是actor和品种对应，导致上下文切换太频繁`src\bin\klagg_simple.rs`
2 所以我有了新版本的方案`docs\文档1.md`,采用线程的分区模型方案
3 我已经实现了新版本的分区模型的demo，`src\bin\klagg_sub_threads.rs`和`src\klagg_sub_threads\mod.rs`
4 你根据我已经实现的actor版本，文档1.md和新版本的分区模型代码，严格，仔细的分析新版本的实现，
功能是否有缺失，逻辑是否严密，数据流程是否严丝合缝，代码实现是否紧凑


1 Watchdog的监控粒度变粗 ，不需要，目前聚焦于实现基础功能
2 动态取消订阅，不需要，因为品种的减少，比品种添加，要更加低频，可能几个月才有一次，这个频次，我手动重启都够了，优先级太低，先实现基础功能
3 特殊Worker”的设计 (逻辑脆弱点)，这个点不用讨论， 已经深入思考过了
4 动态添加品种的流程存在竞态条件 (逻辑漏洞)，添加品种可能一两天才有一个，在这样的频次下，还会有竞态问题吗？
5 I/O循环对动态订阅的处理不健壮 ，这个问题需要修改
6 背压(Back-pressure)问题，没有背压问题，当前处理流程极其高效，不用讨论
7 快照数据冗余，并不会出现这个问题，因为30秒持久化一次，而每个品种的交易数据是每100毫秒更新一次
8 Worker::new 中的 block_on，你是对的，这是坏味道的代码，修改这里
9 硬编码的 NUM_WORKERS。这个目前每问题，服务器环境目前不会变化，就是4个物理核心